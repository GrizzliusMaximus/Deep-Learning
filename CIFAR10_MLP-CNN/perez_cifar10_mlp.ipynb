{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0308 21:50:53.579096 140695746209600 deprecation.py:506] From /home/chico/.virtualenvs/dl4cv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 2,371,594\n",
      "Trainable params: 2,371,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/200, Batch 0/1000, Time 1.357171s/(100 steps)\n",
      "Epoch 1/200, Batch 100/1000, Time 6.283171s/(100 steps)\n",
      "Epoch 1/200, Batch 200/1000, Time 6.312454s/(100 steps)\n",
      "Epoch 1/200, Batch 300/1000, Time 6.302071s/(100 steps)\n",
      "Epoch 1/200, Batch 400/1000, Time 6.332580s/(100 steps)\n",
      "Epoch 1/200, Batch 500/1000, Time 6.331385s/(100 steps)\n",
      "Epoch 1/200, Batch 600/1000, Time 6.254182s/(100 steps)\n",
      "Epoch 1/200, Batch 700/1000, Time 6.307312s/(100 steps)\n",
      "Epoch 1/200, Batch 800/1000, Time 6.327833s/(100 steps)\n",
      "Epoch 1/200, Batch 900/1000, Time 6.361716s/(100 steps)\n",
      "Epoch 1/200, Batch 1000/1000, Time 6.294600s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 1.8331 - acc: 0.3516 - val_loss: 1.7755 - val_acc: 0.4183\n",
      "time 65.076310s\n",
      "Epoch 2/200, Batch 0/1000, Time 0.065091s/(100 steps)\n",
      "Epoch 2/200, Batch 100/1000, Time 6.256642s/(100 steps)\n",
      "Epoch 2/200, Batch 200/1000, Time 6.309986s/(100 steps)\n",
      "Epoch 2/200, Batch 300/1000, Time 6.355727s/(100 steps)\n",
      "Epoch 2/200, Batch 400/1000, Time 6.314017s/(100 steps)\n",
      "Epoch 2/200, Batch 500/1000, Time 6.355923s/(100 steps)\n",
      "Epoch 2/200, Batch 600/1000, Time 6.288805s/(100 steps)\n",
      "Epoch 2/200, Batch 700/1000, Time 6.333254s/(100 steps)\n",
      "Epoch 2/200, Batch 800/1000, Time 6.231708s/(100 steps)\n",
      "Epoch 2/200, Batch 900/1000, Time 6.288808s/(100 steps)\n",
      "Epoch 2/200, Batch 1000/1000, Time 6.334570s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.7427 - acc: 0.4531 - val_loss: 1.6405 - val_acc: 0.4539\n",
      "time 63.670628s\n",
      "Epoch 3/200, Batch 0/1000, Time 0.064821s/(100 steps)\n",
      "Epoch 3/200, Batch 100/1000, Time 6.275776s/(100 steps)\n",
      "Epoch 3/200, Batch 200/1000, Time 6.423457s/(100 steps)\n",
      "Epoch 3/200, Batch 300/1000, Time 6.367816s/(100 steps)\n",
      "Epoch 3/200, Batch 400/1000, Time 6.346687s/(100 steps)\n",
      "Epoch 3/200, Batch 500/1000, Time 6.384871s/(100 steps)\n",
      "Epoch 3/200, Batch 600/1000, Time 6.286071s/(100 steps)\n",
      "Epoch 3/200, Batch 700/1000, Time 6.291657s/(100 steps)\n",
      "Epoch 3/200, Batch 800/1000, Time 6.348698s/(100 steps)\n",
      "Epoch 3/200, Batch 900/1000, Time 6.443175s/(100 steps)\n",
      "Epoch 3/200, Batch 1000/1000, Time 6.385666s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.5430 - acc: 0.4141 - val_loss: 1.5595 - val_acc: 0.4804\n",
      "time 64.150219s\n",
      "Epoch 4/200, Batch 0/1000, Time 0.071415s/(100 steps)\n",
      "Epoch 4/200, Batch 100/1000, Time 6.346715s/(100 steps)\n",
      "Epoch 4/200, Batch 200/1000, Time 6.256310s/(100 steps)\n",
      "Epoch 4/200, Batch 300/1000, Time 6.265910s/(100 steps)\n",
      "Epoch 4/200, Batch 400/1000, Time 6.188944s/(100 steps)\n",
      "Epoch 4/200, Batch 500/1000, Time 6.290416s/(100 steps)\n",
      "Epoch 4/200, Batch 600/1000, Time 6.354861s/(100 steps)\n",
      "Epoch 4/200, Batch 700/1000, Time 6.318429s/(100 steps)\n",
      "Epoch 4/200, Batch 800/1000, Time 6.344849s/(100 steps)\n",
      "Epoch 4/200, Batch 900/1000, Time 6.416960s/(100 steps)\n",
      "Epoch 4/200, Batch 1000/1000, Time 6.337219s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.5552 - acc: 0.5078 - val_loss: 1.4985 - val_acc: 0.4946\n",
      "time 63.714353s\n",
      "Epoch 5/200, Batch 0/1000, Time 0.066715s/(100 steps)\n",
      "Epoch 5/200, Batch 100/1000, Time 6.353080s/(100 steps)\n",
      "Epoch 5/200, Batch 200/1000, Time 6.283911s/(100 steps)\n",
      "Epoch 5/200, Batch 300/1000, Time 6.307100s/(100 steps)\n",
      "Epoch 5/200, Batch 400/1000, Time 6.266589s/(100 steps)\n",
      "Epoch 5/200, Batch 500/1000, Time 6.373551s/(100 steps)\n",
      "Epoch 5/200, Batch 600/1000, Time 6.380851s/(100 steps)\n",
      "Epoch 5/200, Batch 700/1000, Time 6.249020s/(100 steps)\n",
      "Epoch 5/200, Batch 800/1000, Time 6.326335s/(100 steps)\n",
      "Epoch 5/200, Batch 900/1000, Time 6.433600s/(100 steps)\n",
      "Epoch 5/200, Batch 1000/1000, Time 6.367555s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.5471 - acc: 0.4922 - val_loss: 1.4615 - val_acc: 0.5064\n",
      "time 63.928529s\n",
      "Epoch 6/200, Batch 0/1000, Time 0.065937s/(100 steps)\n",
      "Epoch 6/200, Batch 100/1000, Time 6.349719s/(100 steps)\n",
      "Epoch 6/200, Batch 200/1000, Time 6.312144s/(100 steps)\n",
      "Epoch 6/200, Batch 300/1000, Time 6.302186s/(100 steps)\n",
      "Epoch 6/200, Batch 400/1000, Time 6.266252s/(100 steps)\n",
      "Epoch 6/200, Batch 500/1000, Time 6.332262s/(100 steps)\n",
      "Epoch 6/200, Batch 600/1000, Time 6.336100s/(100 steps)\n",
      "Epoch 6/200, Batch 700/1000, Time 6.420211s/(100 steps)\n",
      "Epoch 6/200, Batch 800/1000, Time 6.293235s/(100 steps)\n",
      "Epoch 6/200, Batch 900/1000, Time 6.318903s/(100 steps)\n",
      "Epoch 6/200, Batch 1000/1000, Time 6.250088s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.4221 - acc: 0.5234 - val_loss: 1.4686 - val_acc: 0.5051\n",
      "time 63.767954s\n",
      "Epoch 7/200, Batch 0/1000, Time 0.060780s/(100 steps)\n",
      "Epoch 7/200, Batch 100/1000, Time 6.237385s/(100 steps)\n",
      "Epoch 7/200, Batch 200/1000, Time 6.249614s/(100 steps)\n",
      "Epoch 7/200, Batch 300/1000, Time 6.354066s/(100 steps)\n",
      "Epoch 7/200, Batch 400/1000, Time 6.212226s/(100 steps)\n",
      "Epoch 7/200, Batch 500/1000, Time 6.250141s/(100 steps)\n",
      "Epoch 7/200, Batch 600/1000, Time 6.262592s/(100 steps)\n",
      "Epoch 7/200, Batch 700/1000, Time 6.261283s/(100 steps)\n",
      "Epoch 7/200, Batch 800/1000, Time 6.222805s/(100 steps)\n",
      "Epoch 7/200, Batch 900/1000, Time 6.229737s/(100 steps)\n",
      "Epoch 7/200, Batch 1000/1000, Time 6.322565s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.5334 - acc: 0.4453 - val_loss: 1.4258 - val_acc: 0.5223\n",
      "time 63.193195s\n",
      "Epoch 8/200, Batch 0/1000, Time 0.063237s/(100 steps)\n",
      "Epoch 8/200, Batch 100/1000, Time 6.223271s/(100 steps)\n",
      "Epoch 8/200, Batch 200/1000, Time 6.280142s/(100 steps)\n",
      "Epoch 8/200, Batch 300/1000, Time 6.171417s/(100 steps)\n",
      "Epoch 8/200, Batch 400/1000, Time 6.205019s/(100 steps)\n",
      "Epoch 8/200, Batch 500/1000, Time 6.222820s/(100 steps)\n",
      "Epoch 8/200, Batch 600/1000, Time 6.233906s/(100 steps)\n",
      "Epoch 8/200, Batch 700/1000, Time 6.192691s/(100 steps)\n",
      "Epoch 8/200, Batch 800/1000, Time 6.146541s/(100 steps)\n",
      "Epoch 8/200, Batch 900/1000, Time 6.391165s/(100 steps)\n",
      "Epoch 8/200, Batch 1000/1000, Time 6.237087s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.4633 - acc: 0.5391 - val_loss: 1.4120 - val_acc: 0.5291\n",
      "time 62.896672s\n",
      "Epoch 9/200, Batch 0/1000, Time 0.067093s/(100 steps)\n",
      "Epoch 9/200, Batch 100/1000, Time 6.333138s/(100 steps)\n",
      "Epoch 9/200, Batch 200/1000, Time 6.216463s/(100 steps)\n",
      "Epoch 9/200, Batch 300/1000, Time 6.306225s/(100 steps)\n",
      "Epoch 9/200, Batch 400/1000, Time 6.386933s/(100 steps)\n",
      "Epoch 9/200, Batch 500/1000, Time 6.415674s/(100 steps)\n",
      "Epoch 9/200, Batch 600/1000, Time 6.252146s/(100 steps)\n",
      "Epoch 9/200, Batch 700/1000, Time 6.307095s/(100 steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Batch 800/1000, Time 6.402102s/(100 steps)\n",
      "Epoch 9/200, Batch 900/1000, Time 6.493403s/(100 steps)\n",
      "Epoch 9/200, Batch 1000/1000, Time 6.303911s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.4503 - acc: 0.5078 - val_loss: 1.4133 - val_acc: 0.5335\n",
      "time 64.002394s\n",
      "Epoch 10/200, Batch 0/1000, Time 0.063260s/(100 steps)\n",
      "Epoch 10/200, Batch 100/1000, Time 6.244752s/(100 steps)\n",
      "Epoch 10/200, Batch 200/1000, Time 6.318492s/(100 steps)\n",
      "Epoch 10/200, Batch 300/1000, Time 6.231349s/(100 steps)\n",
      "Epoch 10/200, Batch 400/1000, Time 6.273573s/(100 steps)\n",
      "Epoch 10/200, Batch 500/1000, Time 6.215834s/(100 steps)\n",
      "Epoch 10/200, Batch 600/1000, Time 6.296014s/(100 steps)\n",
      "Epoch 10/200, Batch 700/1000, Time 6.287224s/(100 steps)\n",
      "Epoch 10/200, Batch 800/1000, Time 6.269997s/(100 steps)\n",
      "Epoch 10/200, Batch 900/1000, Time 6.277798s/(100 steps)\n",
      "Epoch 10/200, Batch 1000/1000, Time 6.305770s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.4247 - acc: 0.4922 - val_loss: 1.3757 - val_acc: 0.5436\n",
      "time 63.308872s\n",
      "Epoch 11/200, Batch 0/1000, Time 0.062633s/(100 steps)\n",
      "Epoch 11/200, Batch 100/1000, Time 6.265796s/(100 steps)\n",
      "Epoch 11/200, Batch 200/1000, Time 6.274256s/(100 steps)\n",
      "Epoch 11/200, Batch 300/1000, Time 6.206590s/(100 steps)\n",
      "Epoch 11/200, Batch 400/1000, Time 6.276941s/(100 steps)\n",
      "Epoch 11/200, Batch 500/1000, Time 6.161326s/(100 steps)\n",
      "Epoch 11/200, Batch 600/1000, Time 6.193671s/(100 steps)\n",
      "Epoch 11/200, Batch 700/1000, Time 6.277037s/(100 steps)\n",
      "Epoch 11/200, Batch 800/1000, Time 6.122381s/(100 steps)\n",
      "Epoch 11/200, Batch 900/1000, Time 6.252237s/(100 steps)\n",
      "Epoch 11/200, Batch 1000/1000, Time 6.326407s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3070 - acc: 0.5000 - val_loss: 1.3877 - val_acc: 0.5318\n",
      "time 62.942888s\n",
      "Epoch 12/200, Batch 0/1000, Time 0.062744s/(100 steps)\n",
      "Epoch 12/200, Batch 100/1000, Time 6.340951s/(100 steps)\n",
      "Epoch 12/200, Batch 200/1000, Time 6.324635s/(100 steps)\n",
      "Epoch 12/200, Batch 300/1000, Time 6.308062s/(100 steps)\n",
      "Epoch 12/200, Batch 400/1000, Time 6.434046s/(100 steps)\n",
      "Epoch 12/200, Batch 500/1000, Time 6.564520s/(100 steps)\n",
      "Epoch 12/200, Batch 600/1000, Time 6.572850s/(100 steps)\n",
      "Epoch 12/200, Batch 700/1000, Time 6.397651s/(100 steps)\n",
      "Epoch 12/200, Batch 800/1000, Time 6.276083s/(100 steps)\n",
      "Epoch 12/200, Batch 900/1000, Time 6.261035s/(100 steps)\n",
      "Epoch 12/200, Batch 1000/1000, Time 6.282208s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3154 - acc: 0.5312 - val_loss: 1.3368 - val_acc: 0.5500\n",
      "time 64.371631s\n",
      "Epoch 13/200, Batch 0/1000, Time 0.066245s/(100 steps)\n",
      "Epoch 13/200, Batch 100/1000, Time 6.418520s/(100 steps)\n",
      "Epoch 13/200, Batch 200/1000, Time 6.358819s/(100 steps)\n",
      "Epoch 13/200, Batch 300/1000, Time 6.383943s/(100 steps)\n",
      "Epoch 13/200, Batch 400/1000, Time 6.326319s/(100 steps)\n",
      "Epoch 13/200, Batch 500/1000, Time 6.388135s/(100 steps)\n",
      "Epoch 13/200, Batch 600/1000, Time 6.317091s/(100 steps)\n",
      "Epoch 13/200, Batch 700/1000, Time 6.291413s/(100 steps)\n",
      "Epoch 13/200, Batch 800/1000, Time 6.352470s/(100 steps)\n",
      "Epoch 13/200, Batch 900/1000, Time 6.431815s/(100 steps)\n",
      "Epoch 13/200, Batch 1000/1000, Time 6.322172s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2401 - acc: 0.6016 - val_loss: 1.3581 - val_acc: 0.5438\n",
      "time 64.191553s\n",
      "Epoch 14/200, Batch 0/1000, Time 0.062914s/(100 steps)\n",
      "Epoch 14/200, Batch 100/1000, Time 6.337655s/(100 steps)\n",
      "Epoch 14/200, Batch 200/1000, Time 6.294755s/(100 steps)\n",
      "Epoch 14/200, Batch 300/1000, Time 6.241007s/(100 steps)\n",
      "Epoch 14/200, Batch 400/1000, Time 6.253219s/(100 steps)\n",
      "Epoch 14/200, Batch 500/1000, Time 6.375660s/(100 steps)\n",
      "Epoch 14/200, Batch 600/1000, Time 6.374048s/(100 steps)\n",
      "Epoch 14/200, Batch 700/1000, Time 6.293370s/(100 steps)\n",
      "Epoch 14/200, Batch 800/1000, Time 6.341770s/(100 steps)\n",
      "Epoch 14/200, Batch 900/1000, Time 6.217968s/(100 steps)\n",
      "Epoch 14/200, Batch 1000/1000, Time 6.245098s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.4649 - acc: 0.5078 - val_loss: 1.3382 - val_acc: 0.5511\n",
      "time 63.547845s\n",
      "Epoch 15/200, Batch 0/1000, Time 0.064725s/(100 steps)\n",
      "Epoch 15/200, Batch 100/1000, Time 6.339590s/(100 steps)\n",
      "Epoch 15/200, Batch 200/1000, Time 6.336499s/(100 steps)\n",
      "Epoch 15/200, Batch 300/1000, Time 6.304573s/(100 steps)\n",
      "Epoch 15/200, Batch 400/1000, Time 6.273885s/(100 steps)\n",
      "Epoch 15/200, Batch 500/1000, Time 6.302272s/(100 steps)\n",
      "Epoch 15/200, Batch 600/1000, Time 6.341010s/(100 steps)\n",
      "Epoch 15/200, Batch 700/1000, Time 6.438474s/(100 steps)\n",
      "Epoch 15/200, Batch 800/1000, Time 6.376408s/(100 steps)\n",
      "Epoch 15/200, Batch 900/1000, Time 6.359806s/(100 steps)\n",
      "Epoch 15/200, Batch 1000/1000, Time 6.298117s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.5653 - acc: 0.5000 - val_loss: 1.3357 - val_acc: 0.5522\n",
      "time 63.972258s\n",
      "Epoch 16/200, Batch 0/1000, Time 0.068894s/(100 steps)\n",
      "Epoch 16/200, Batch 100/1000, Time 6.321063s/(100 steps)\n",
      "Epoch 16/200, Batch 200/1000, Time 6.289617s/(100 steps)\n",
      "Epoch 16/200, Batch 300/1000, Time 6.341122s/(100 steps)\n",
      "Epoch 16/200, Batch 400/1000, Time 6.281480s/(100 steps)\n",
      "Epoch 16/200, Batch 500/1000, Time 6.327782s/(100 steps)\n",
      "Epoch 16/200, Batch 600/1000, Time 6.533437s/(100 steps)\n",
      "Epoch 16/200, Batch 700/1000, Time 6.416162s/(100 steps)\n",
      "Epoch 16/200, Batch 800/1000, Time 6.438113s/(100 steps)\n",
      "Epoch 16/200, Batch 900/1000, Time 6.319939s/(100 steps)\n",
      "Epoch 16/200, Batch 1000/1000, Time 6.363744s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.6658 - acc: 0.4766 - val_loss: 1.3187 - val_acc: 0.5634\n",
      "time 64.241664s\n",
      "Epoch 17/200, Batch 0/1000, Time 0.059556s/(100 steps)\n",
      "Epoch 17/200, Batch 100/1000, Time 6.318850s/(100 steps)\n",
      "Epoch 17/200, Batch 200/1000, Time 6.269824s/(100 steps)\n",
      "Epoch 17/200, Batch 300/1000, Time 6.249906s/(100 steps)\n",
      "Epoch 17/200, Batch 400/1000, Time 6.184035s/(100 steps)\n",
      "Epoch 17/200, Batch 500/1000, Time 6.323314s/(100 steps)\n",
      "Epoch 17/200, Batch 600/1000, Time 6.289814s/(100 steps)\n",
      "Epoch 17/200, Batch 700/1000, Time 6.261640s/(100 steps)\n",
      "Epoch 17/200, Batch 800/1000, Time 6.223737s/(100 steps)\n",
      "Epoch 17/200, Batch 900/1000, Time 6.486991s/(100 steps)\n",
      "Epoch 17/200, Batch 1000/1000, Time 6.353132s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2759 - acc: 0.5859 - val_loss: 1.3194 - val_acc: 0.5537\n",
      "time 63.561447s\n",
      "Epoch 18/200, Batch 0/1000, Time 0.070393s/(100 steps)\n",
      "Epoch 18/200, Batch 100/1000, Time 6.402591s/(100 steps)\n",
      "Epoch 18/200, Batch 200/1000, Time 6.355671s/(100 steps)\n",
      "Epoch 18/200, Batch 300/1000, Time 6.442142s/(100 steps)\n",
      "Epoch 18/200, Batch 400/1000, Time 6.335647s/(100 steps)\n",
      "Epoch 18/200, Batch 500/1000, Time 6.252753s/(100 steps)\n",
      "Epoch 18/200, Batch 600/1000, Time 6.291524s/(100 steps)\n",
      "Epoch 18/200, Batch 700/1000, Time 6.253934s/(100 steps)\n",
      "Epoch 18/200, Batch 800/1000, Time 6.330453s/(100 steps)\n",
      "Epoch 18/200, Batch 900/1000, Time 6.248980s/(100 steps)\n",
      "Epoch 18/200, Batch 1000/1000, Time 6.269029s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.4024 - acc: 0.5156 - val_loss: 1.2950 - val_acc: 0.5646\n",
      "time 63.776020s\n",
      "Epoch 19/200, Batch 0/1000, Time 0.061306s/(100 steps)\n",
      "Epoch 19/200, Batch 100/1000, Time 6.278491s/(100 steps)\n",
      "Epoch 19/200, Batch 200/1000, Time 6.365384s/(100 steps)\n",
      "Epoch 19/200, Batch 300/1000, Time 6.251961s/(100 steps)\n",
      "Epoch 19/200, Batch 400/1000, Time 6.302642s/(100 steps)\n",
      "Epoch 19/200, Batch 500/1000, Time 6.359972s/(100 steps)\n",
      "Epoch 19/200, Batch 600/1000, Time 6.339411s/(100 steps)\n",
      "Epoch 19/200, Batch 700/1000, Time 6.329450s/(100 steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200, Batch 800/1000, Time 6.381075s/(100 steps)\n",
      "Epoch 19/200, Batch 900/1000, Time 6.315120s/(100 steps)\n",
      "Epoch 19/200, Batch 1000/1000, Time 6.290143s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.4194 - acc: 0.5391 - val_loss: 1.3006 - val_acc: 0.5630\n",
      "time 63.792948s\n",
      "Epoch 20/200, Batch 0/1000, Time 0.071537s/(100 steps)\n",
      "Epoch 20/200, Batch 100/1000, Time 6.310874s/(100 steps)\n",
      "Epoch 20/200, Batch 200/1000, Time 6.393045s/(100 steps)\n",
      "Epoch 20/200, Batch 300/1000, Time 6.413408s/(100 steps)\n",
      "Epoch 20/200, Batch 400/1000, Time 6.430030s/(100 steps)\n",
      "Epoch 20/200, Batch 500/1000, Time 6.426870s/(100 steps)\n",
      "Epoch 20/200, Batch 600/1000, Time 6.318576s/(100 steps)\n",
      "Epoch 20/200, Batch 700/1000, Time 6.318490s/(100 steps)\n",
      "Epoch 20/200, Batch 800/1000, Time 6.336920s/(100 steps)\n",
      "Epoch 20/200, Batch 900/1000, Time 6.452306s/(100 steps)\n",
      "Epoch 20/200, Batch 1000/1000, Time 6.362679s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.4329 - acc: 0.5156 - val_loss: 1.2890 - val_acc: 0.5684\n",
      "time 64.353540s\n",
      "Epoch 21/200, Batch 0/1000, Time 0.067492s/(100 steps)\n",
      "Epoch 21/200, Batch 100/1000, Time 6.328382s/(100 steps)\n",
      "Epoch 21/200, Batch 200/1000, Time 6.312982s/(100 steps)\n",
      "Epoch 21/200, Batch 300/1000, Time 6.227905s/(100 steps)\n",
      "Epoch 21/200, Batch 400/1000, Time 6.203061s/(100 steps)\n",
      "Epoch 21/200, Batch 500/1000, Time 6.289315s/(100 steps)\n",
      "Epoch 21/200, Batch 600/1000, Time 6.243653s/(100 steps)\n",
      "Epoch 21/200, Batch 700/1000, Time 6.273532s/(100 steps)\n",
      "Epoch 21/200, Batch 800/1000, Time 6.222958s/(100 steps)\n",
      "Epoch 21/200, Batch 900/1000, Time 6.295283s/(100 steps)\n",
      "Epoch 21/200, Batch 1000/1000, Time 6.322557s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2916 - acc: 0.6484 - val_loss: 1.2848 - val_acc: 0.5709\n",
      "time 63.305221s\n",
      "Epoch 22/200, Batch 0/1000, Time 0.063323s/(100 steps)\n",
      "Epoch 22/200, Batch 100/1000, Time 6.312141s/(100 steps)\n",
      "Epoch 22/200, Batch 200/1000, Time 6.292355s/(100 steps)\n",
      "Epoch 22/200, Batch 300/1000, Time 6.295864s/(100 steps)\n",
      "Epoch 22/200, Batch 400/1000, Time 6.250362s/(100 steps)\n",
      "Epoch 22/200, Batch 500/1000, Time 6.283092s/(100 steps)\n",
      "Epoch 22/200, Batch 600/1000, Time 6.258202s/(100 steps)\n",
      "Epoch 22/200, Batch 700/1000, Time 6.328859s/(100 steps)\n",
      "Epoch 22/200, Batch 800/1000, Time 6.387376s/(100 steps)\n",
      "Epoch 22/200, Batch 900/1000, Time 6.281387s/(100 steps)\n",
      "Epoch 22/200, Batch 1000/1000, Time 6.274000s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2842 - acc: 0.5469 - val_loss: 1.2725 - val_acc: 0.5728\n",
      "time 63.542833s\n",
      "Epoch 23/200, Batch 0/1000, Time 0.067233s/(100 steps)\n",
      "Epoch 23/200, Batch 100/1000, Time 6.256633s/(100 steps)\n",
      "Epoch 23/200, Batch 200/1000, Time 6.282193s/(100 steps)\n",
      "Epoch 23/200, Batch 300/1000, Time 6.294096s/(100 steps)\n",
      "Epoch 23/200, Batch 400/1000, Time 6.206851s/(100 steps)\n",
      "Epoch 23/200, Batch 500/1000, Time 6.224451s/(100 steps)\n",
      "Epoch 23/200, Batch 600/1000, Time 6.289054s/(100 steps)\n",
      "Epoch 23/200, Batch 700/1000, Time 6.315329s/(100 steps)\n",
      "Epoch 23/200, Batch 800/1000, Time 6.314139s/(100 steps)\n",
      "Epoch 23/200, Batch 900/1000, Time 6.301554s/(100 steps)\n",
      "Epoch 23/200, Batch 1000/1000, Time 6.178051s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.0669 - acc: 0.6562 - val_loss: 1.2849 - val_acc: 0.5733\n",
      "time 63.259785s\n",
      "Epoch 24/200, Batch 0/1000, Time 0.066706s/(100 steps)\n",
      "Epoch 24/200, Batch 100/1000, Time 6.383581s/(100 steps)\n",
      "Epoch 24/200, Batch 200/1000, Time 6.250888s/(100 steps)\n",
      "Epoch 24/200, Batch 300/1000, Time 6.282592s/(100 steps)\n",
      "Epoch 24/200, Batch 400/1000, Time 6.225652s/(100 steps)\n",
      "Epoch 24/200, Batch 500/1000, Time 6.224542s/(100 steps)\n",
      "Epoch 24/200, Batch 600/1000, Time 6.323723s/(100 steps)\n",
      "Epoch 24/200, Batch 700/1000, Time 6.490078s/(100 steps)\n",
      "Epoch 24/200, Batch 800/1000, Time 6.240113s/(100 steps)\n",
      "Epoch 24/200, Batch 900/1000, Time 6.342069s/(100 steps)\n",
      "Epoch 24/200, Batch 1000/1000, Time 6.329425s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3198 - acc: 0.5469 - val_loss: 1.2757 - val_acc: 0.5753\n",
      "time 63.678933s\n",
      "Epoch 25/200, Batch 0/1000, Time 0.070050s/(100 steps)\n",
      "Epoch 25/200, Batch 100/1000, Time 6.462774s/(100 steps)\n",
      "Epoch 25/200, Batch 200/1000, Time 6.347231s/(100 steps)\n",
      "Epoch 25/200, Batch 300/1000, Time 6.361946s/(100 steps)\n",
      "Epoch 25/200, Batch 400/1000, Time 6.258366s/(100 steps)\n",
      "Epoch 25/200, Batch 500/1000, Time 6.291788s/(100 steps)\n",
      "Epoch 25/200, Batch 600/1000, Time 6.218670s/(100 steps)\n",
      "Epoch 25/200, Batch 700/1000, Time 6.240180s/(100 steps)\n",
      "Epoch 25/200, Batch 800/1000, Time 6.279957s/(100 steps)\n",
      "Epoch 25/200, Batch 900/1000, Time 6.261643s/(100 steps)\n",
      "Epoch 25/200, Batch 1000/1000, Time 6.279652s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.4885 - acc: 0.4922 - val_loss: 1.2821 - val_acc: 0.5794\n",
      "time 63.597179s\n",
      "Epoch 26/200, Batch 0/1000, Time 0.070214s/(100 steps)\n",
      "Epoch 26/200, Batch 100/1000, Time 6.224317s/(100 steps)\n",
      "Epoch 26/200, Batch 200/1000, Time 6.251344s/(100 steps)\n",
      "Epoch 26/200, Batch 300/1000, Time 6.259008s/(100 steps)\n",
      "Epoch 26/200, Batch 400/1000, Time 6.352579s/(100 steps)\n",
      "Epoch 26/200, Batch 500/1000, Time 6.407697s/(100 steps)\n",
      "Epoch 26/200, Batch 600/1000, Time 6.456187s/(100 steps)\n",
      "Epoch 26/200, Batch 700/1000, Time 6.410004s/(100 steps)\n",
      "Epoch 26/200, Batch 800/1000, Time 6.257736s/(100 steps)\n",
      "Epoch 26/200, Batch 900/1000, Time 6.242267s/(100 steps)\n",
      "Epoch 26/200, Batch 1000/1000, Time 6.314899s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2994 - acc: 0.5625 - val_loss: 1.2918 - val_acc: 0.5653\n",
      "time 63.767515s\n",
      "Epoch 27/200, Batch 0/1000, Time 0.068747s/(100 steps)\n",
      "Epoch 27/200, Batch 100/1000, Time 6.325939s/(100 steps)\n",
      "Epoch 27/200, Batch 200/1000, Time 6.296015s/(100 steps)\n",
      "Epoch 27/200, Batch 300/1000, Time 6.425985s/(100 steps)\n",
      "Epoch 27/200, Batch 400/1000, Time 6.312474s/(100 steps)\n",
      "Epoch 27/200, Batch 500/1000, Time 6.315218s/(100 steps)\n",
      "Epoch 27/200, Batch 600/1000, Time 6.337547s/(100 steps)\n",
      "Epoch 27/200, Batch 700/1000, Time 6.248762s/(100 steps)\n",
      "Epoch 27/200, Batch 800/1000, Time 6.424910s/(100 steps)\n",
      "Epoch 27/200, Batch 900/1000, Time 6.412886s/(100 steps)\n",
      "Epoch 27/200, Batch 1000/1000, Time 6.380101s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3636 - acc: 0.5469 - val_loss: 1.2614 - val_acc: 0.5810\n",
      "time 64.082682s\n",
      "Epoch 28/200, Batch 0/1000, Time 0.066461s/(100 steps)\n",
      "Epoch 28/200, Batch 100/1000, Time 6.495770s/(100 steps)\n",
      "Epoch 28/200, Batch 200/1000, Time 6.428410s/(100 steps)\n",
      "Epoch 28/200, Batch 300/1000, Time 6.290427s/(100 steps)\n",
      "Epoch 28/200, Batch 400/1000, Time 6.465596s/(100 steps)\n",
      "Epoch 28/200, Batch 500/1000, Time 6.284522s/(100 steps)\n",
      "Epoch 28/200, Batch 600/1000, Time 6.360012s/(100 steps)\n",
      "Epoch 28/200, Batch 700/1000, Time 6.273030s/(100 steps)\n",
      "Epoch 28/200, Batch 800/1000, Time 6.238652s/(100 steps)\n",
      "Epoch 28/200, Batch 900/1000, Time 6.263396s/(100 steps)\n",
      "Epoch 28/200, Batch 1000/1000, Time 6.303465s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3282 - acc: 0.5859 - val_loss: 1.2869 - val_acc: 0.5675\n",
      "time 63.991802s\n",
      "Epoch 29/200, Batch 0/1000, Time 0.063964s/(100 steps)\n",
      "Epoch 29/200, Batch 100/1000, Time 6.252208s/(100 steps)\n",
      "Epoch 29/200, Batch 200/1000, Time 6.278180s/(100 steps)\n",
      "Epoch 29/200, Batch 300/1000, Time 6.405003s/(100 steps)\n",
      "Epoch 29/200, Batch 400/1000, Time 6.381696s/(100 steps)\n",
      "Epoch 29/200, Batch 500/1000, Time 6.472656s/(100 steps)\n",
      "Epoch 29/200, Batch 600/1000, Time 6.375589s/(100 steps)\n",
      "Epoch 29/200, Batch 700/1000, Time 6.318467s/(100 steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200, Batch 800/1000, Time 6.310327s/(100 steps)\n",
      "Epoch 29/200, Batch 900/1000, Time 6.364148s/(100 steps)\n",
      "Epoch 29/200, Batch 1000/1000, Time 6.313384s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3937 - acc: 0.5000 - val_loss: 1.2891 - val_acc: 0.5747\n",
      "time 64.060071s\n",
      "Epoch 30/200, Batch 0/1000, Time 0.067455s/(100 steps)\n",
      "Epoch 30/200, Batch 100/1000, Time 6.300825s/(100 steps)\n",
      "Epoch 30/200, Batch 200/1000, Time 6.322637s/(100 steps)\n",
      "Epoch 30/200, Batch 300/1000, Time 6.368633s/(100 steps)\n",
      "Epoch 30/200, Batch 400/1000, Time 6.291096s/(100 steps)\n",
      "Epoch 30/200, Batch 500/1000, Time 6.471962s/(100 steps)\n",
      "Epoch 30/200, Batch 600/1000, Time 6.465909s/(100 steps)\n",
      "Epoch 30/200, Batch 700/1000, Time 6.330519s/(100 steps)\n",
      "Epoch 30/200, Batch 800/1000, Time 6.273644s/(100 steps)\n",
      "Epoch 30/200, Batch 900/1000, Time 6.393732s/(100 steps)\n",
      "Epoch 30/200, Batch 1000/1000, Time 6.261497s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2022 - acc: 0.6016 - val_loss: 1.2531 - val_acc: 0.5867\n",
      "time 64.063385s\n",
      "Epoch 31/200, Batch 0/1000, Time 0.064143s/(100 steps)\n",
      "Epoch 31/200, Batch 100/1000, Time 6.300273s/(100 steps)\n",
      "Epoch 31/200, Batch 200/1000, Time 6.314775s/(100 steps)\n",
      "Epoch 31/200, Batch 300/1000, Time 6.306815s/(100 steps)\n",
      "Epoch 31/200, Batch 400/1000, Time 6.336898s/(100 steps)\n",
      "Epoch 31/200, Batch 500/1000, Time 6.297769s/(100 steps)\n",
      "Epoch 31/200, Batch 600/1000, Time 6.363493s/(100 steps)\n",
      "Epoch 31/200, Batch 700/1000, Time 6.483894s/(100 steps)\n",
      "Epoch 31/200, Batch 800/1000, Time 6.407285s/(100 steps)\n",
      "Epoch 31/200, Batch 900/1000, Time 6.492176s/(100 steps)\n",
      "Epoch 31/200, Batch 1000/1000, Time 6.323143s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2332 - acc: 0.6172 - val_loss: 1.2440 - val_acc: 0.5872\n",
      "time 64.214845s\n",
      "Epoch 32/200, Batch 0/1000, Time 0.066652s/(100 steps)\n",
      "Epoch 32/200, Batch 100/1000, Time 6.296757s/(100 steps)\n",
      "Epoch 32/200, Batch 200/1000, Time 6.331550s/(100 steps)\n",
      "Epoch 32/200, Batch 300/1000, Time 6.264551s/(100 steps)\n",
      "Epoch 32/200, Batch 400/1000, Time 6.245366s/(100 steps)\n",
      "Epoch 32/200, Batch 500/1000, Time 6.338278s/(100 steps)\n",
      "Epoch 32/200, Batch 600/1000, Time 6.267662s/(100 steps)\n",
      "Epoch 32/200, Batch 700/1000, Time 6.285834s/(100 steps)\n",
      "Epoch 32/200, Batch 800/1000, Time 6.324655s/(100 steps)\n",
      "Epoch 32/200, Batch 900/1000, Time 6.401145s/(100 steps)\n",
      "Epoch 32/200, Batch 1000/1000, Time 6.255781s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2503 - acc: 0.6172 - val_loss: 1.2577 - val_acc: 0.5862\n",
      "time 63.608478s\n",
      "Epoch 33/200, Batch 0/1000, Time 0.066099s/(100 steps)\n",
      "Epoch 33/200, Batch 100/1000, Time 6.309568s/(100 steps)\n",
      "Epoch 33/200, Batch 200/1000, Time 6.252655s/(100 steps)\n",
      "Epoch 33/200, Batch 300/1000, Time 6.273122s/(100 steps)\n",
      "Epoch 33/200, Batch 400/1000, Time 6.219298s/(100 steps)\n",
      "Epoch 33/200, Batch 500/1000, Time 6.275233s/(100 steps)\n",
      "Epoch 33/200, Batch 600/1000, Time 6.234460s/(100 steps)\n",
      "Epoch 33/200, Batch 700/1000, Time 6.245375s/(100 steps)\n",
      "Epoch 33/200, Batch 800/1000, Time 6.189519s/(100 steps)\n",
      "Epoch 33/200, Batch 900/1000, Time 6.256158s/(100 steps)\n",
      "Epoch 33/200, Batch 1000/1000, Time 6.289254s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2155 - acc: 0.6484 - val_loss: 1.2643 - val_acc: 0.5783\n",
      "time 63.125523s\n",
      "Epoch 34/200, Batch 0/1000, Time 0.066304s/(100 steps)\n",
      "Epoch 34/200, Batch 100/1000, Time 6.210615s/(100 steps)\n",
      "Epoch 34/200, Batch 200/1000, Time 6.248836s/(100 steps)\n",
      "Epoch 34/200, Batch 300/1000, Time 6.323221s/(100 steps)\n",
      "Epoch 34/200, Batch 400/1000, Time 6.199765s/(100 steps)\n",
      "Epoch 34/200, Batch 500/1000, Time 6.251197s/(100 steps)\n",
      "Epoch 34/200, Batch 600/1000, Time 6.243057s/(100 steps)\n",
      "Epoch 34/200, Batch 700/1000, Time 6.318219s/(100 steps)\n",
      "Epoch 34/200, Batch 800/1000, Time 6.269262s/(100 steps)\n",
      "Epoch 34/200, Batch 900/1000, Time 6.324082s/(100 steps)\n",
      "Epoch 34/200, Batch 1000/1000, Time 6.296120s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 1.4254 - acc: 0.4922 - val_loss: 1.2578 - val_acc: 0.5813\n",
      "time 63.254066s\n",
      "Epoch 35/200, Batch 0/1000, Time 0.063046s/(100 steps)\n",
      "Epoch 35/200, Batch 100/1000, Time 6.462069s/(100 steps)\n",
      "Epoch 35/200, Batch 200/1000, Time 6.544769s/(100 steps)\n",
      "Epoch 35/200, Batch 300/1000, Time 6.389503s/(100 steps)\n",
      "Epoch 35/200, Batch 400/1000, Time 6.299629s/(100 steps)\n",
      "Epoch 35/200, Batch 500/1000, Time 6.350298s/(100 steps)\n",
      "Epoch 35/200, Batch 600/1000, Time 6.484152s/(100 steps)\n",
      "Epoch 35/200, Batch 700/1000, Time 6.350535s/(100 steps)\n",
      "Epoch 35/200, Batch 800/1000, Time 6.363396s/(100 steps)\n",
      "Epoch 35/200, Batch 900/1000, Time 6.324117s/(100 steps)\n",
      "Epoch 35/200, Batch 1000/1000, Time 6.408793s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3320 - acc: 0.5547 - val_loss: 1.2508 - val_acc: 0.5829\n",
      "time 64.568739s\n",
      "Epoch 36/200, Batch 0/1000, Time 0.070572s/(100 steps)\n",
      "Epoch 36/200, Batch 100/1000, Time 6.383268s/(100 steps)\n",
      "Epoch 36/200, Batch 200/1000, Time 6.250955s/(100 steps)\n",
      "Epoch 36/200, Batch 300/1000, Time 6.275041s/(100 steps)\n",
      "Epoch 36/200, Batch 400/1000, Time 6.258703s/(100 steps)\n",
      "Epoch 36/200, Batch 500/1000, Time 6.363591s/(100 steps)\n",
      "Epoch 36/200, Batch 600/1000, Time 6.289191s/(100 steps)\n",
      "Epoch 36/200, Batch 700/1000, Time 6.333262s/(100 steps)\n",
      "Epoch 36/200, Batch 800/1000, Time 6.529378s/(100 steps)\n",
      "Epoch 36/200, Batch 900/1000, Time 6.247915s/(100 steps)\n",
      "Epoch 36/200, Batch 1000/1000, Time 6.321991s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2811 - acc: 0.5391 - val_loss: 1.2399 - val_acc: 0.5897\n",
      "time 63.843287s\n",
      "Epoch 37/200, Batch 0/1000, Time 0.056995s/(100 steps)\n",
      "Epoch 37/200, Batch 100/1000, Time 6.246130s/(100 steps)\n",
      "Epoch 37/200, Batch 200/1000, Time 6.312797s/(100 steps)\n",
      "Epoch 37/200, Batch 300/1000, Time 6.318937s/(100 steps)\n",
      "Epoch 37/200, Batch 400/1000, Time 6.361394s/(100 steps)\n",
      "Epoch 37/200, Batch 500/1000, Time 6.281439s/(100 steps)\n",
      "Epoch 37/200, Batch 600/1000, Time 6.228791s/(100 steps)\n",
      "Epoch 37/200, Batch 700/1000, Time 6.425293s/(100 steps)\n",
      "Epoch 37/200, Batch 800/1000, Time 6.322309s/(100 steps)\n",
      "Epoch 37/200, Batch 900/1000, Time 6.312157s/(100 steps)\n",
      "Epoch 37/200, Batch 1000/1000, Time 6.248175s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1707 - acc: 0.6016 - val_loss: 1.2363 - val_acc: 0.5933\n",
      "time 63.644406s\n",
      "Epoch 38/200, Batch 0/1000, Time 0.062481s/(100 steps)\n",
      "Epoch 38/200, Batch 100/1000, Time 6.274001s/(100 steps)\n",
      "Epoch 38/200, Batch 200/1000, Time 6.356654s/(100 steps)\n",
      "Epoch 38/200, Batch 300/1000, Time 6.415611s/(100 steps)\n",
      "Epoch 38/200, Batch 400/1000, Time 6.298450s/(100 steps)\n",
      "Epoch 38/200, Batch 500/1000, Time 6.343521s/(100 steps)\n",
      "Epoch 38/200, Batch 600/1000, Time 6.290514s/(100 steps)\n",
      "Epoch 38/200, Batch 700/1000, Time 6.278677s/(100 steps)\n",
      "Epoch 38/200, Batch 800/1000, Time 6.272897s/(100 steps)\n",
      "Epoch 38/200, Batch 900/1000, Time 6.282866s/(100 steps)\n",
      "Epoch 38/200, Batch 1000/1000, Time 6.284184s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.0568 - acc: 0.6719 - val_loss: 1.2310 - val_acc: 0.5986\n",
      "time 63.697098s\n",
      "Epoch 39/200, Batch 0/1000, Time 0.069111s/(100 steps)\n",
      "Epoch 39/200, Batch 100/1000, Time 6.303629s/(100 steps)\n",
      "Epoch 39/200, Batch 200/1000, Time 6.324258s/(100 steps)\n",
      "Epoch 39/200, Batch 300/1000, Time 6.455697s/(100 steps)\n",
      "Epoch 39/200, Batch 400/1000, Time 6.399972s/(100 steps)\n",
      "Epoch 39/200, Batch 500/1000, Time 6.402230s/(100 steps)\n",
      "Epoch 39/200, Batch 600/1000, Time 6.492660s/(100 steps)\n",
      "Epoch 39/200, Batch 700/1000, Time 6.291717s/(100 steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200, Batch 800/1000, Time 6.395101s/(100 steps)\n",
      "Epoch 39/200, Batch 900/1000, Time 6.406995s/(100 steps)\n",
      "Epoch 39/200, Batch 1000/1000, Time 6.338317s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1120 - acc: 0.6641 - val_loss: 1.2327 - val_acc: 0.5931\n",
      "time 64.388855s\n",
      "Epoch 40/200, Batch 0/1000, Time 0.065929s/(100 steps)\n",
      "Epoch 40/200, Batch 100/1000, Time 6.381631s/(100 steps)\n",
      "Epoch 40/200, Batch 200/1000, Time 6.317923s/(100 steps)\n",
      "Epoch 40/200, Batch 300/1000, Time 6.440482s/(100 steps)\n",
      "Epoch 40/200, Batch 400/1000, Time 6.291988s/(100 steps)\n",
      "Epoch 40/200, Batch 500/1000, Time 6.475535s/(100 steps)\n",
      "Epoch 40/200, Batch 600/1000, Time 6.292812s/(100 steps)\n",
      "Epoch 40/200, Batch 700/1000, Time 6.327480s/(100 steps)\n",
      "Epoch 40/200, Batch 800/1000, Time 6.292365s/(100 steps)\n",
      "Epoch 40/200, Batch 900/1000, Time 6.312630s/(100 steps)\n",
      "Epoch 40/200, Batch 1000/1000, Time 6.265893s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3258 - acc: 0.5391 - val_loss: 1.2304 - val_acc: 0.5963\n",
      "time 64.005269s\n",
      "Epoch 41/200, Batch 0/1000, Time 0.071159s/(100 steps)\n",
      "Epoch 41/200, Batch 100/1000, Time 6.309489s/(100 steps)\n",
      "Epoch 41/200, Batch 200/1000, Time 6.371264s/(100 steps)\n",
      "Epoch 41/200, Batch 300/1000, Time 6.388686s/(100 steps)\n",
      "Epoch 41/200, Batch 400/1000, Time 6.352047s/(100 steps)\n",
      "Epoch 41/200, Batch 500/1000, Time 6.345470s/(100 steps)\n",
      "Epoch 41/200, Batch 600/1000, Time 6.352830s/(100 steps)\n",
      "Epoch 41/200, Batch 700/1000, Time 6.415979s/(100 steps)\n",
      "Epoch 41/200, Batch 800/1000, Time 6.406555s/(100 steps)\n",
      "Epoch 41/200, Batch 900/1000, Time 6.346998s/(100 steps)\n",
      "Epoch 41/200, Batch 1000/1000, Time 6.331953s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1490 - acc: 0.6172 - val_loss: 1.2371 - val_acc: 0.5859\n",
      "time 64.196405s\n",
      "Epoch 42/200, Batch 0/1000, Time 0.067865s/(100 steps)\n",
      "Epoch 42/200, Batch 100/1000, Time 6.441433s/(100 steps)\n",
      "Epoch 42/200, Batch 200/1000, Time 6.334234s/(100 steps)\n",
      "Epoch 42/200, Batch 300/1000, Time 6.292063s/(100 steps)\n",
      "Epoch 42/200, Batch 400/1000, Time 6.477921s/(100 steps)\n",
      "Epoch 42/200, Batch 500/1000, Time 6.375516s/(100 steps)\n",
      "Epoch 42/200, Batch 600/1000, Time 6.343105s/(100 steps)\n",
      "Epoch 42/200, Batch 700/1000, Time 6.395395s/(100 steps)\n",
      "Epoch 42/200, Batch 800/1000, Time 6.317654s/(100 steps)\n",
      "Epoch 42/200, Batch 900/1000, Time 6.319845s/(100 steps)\n",
      "Epoch 42/200, Batch 1000/1000, Time 6.465367s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2571 - acc: 0.5938 - val_loss: 1.2372 - val_acc: 0.5896\n",
      "time 64.346134s\n",
      "Epoch 43/200, Batch 0/1000, Time 0.065874s/(100 steps)\n",
      "Epoch 43/200, Batch 100/1000, Time 6.448093s/(100 steps)\n",
      "Epoch 43/200, Batch 200/1000, Time 6.448934s/(100 steps)\n",
      "Epoch 43/200, Batch 300/1000, Time 6.463159s/(100 steps)\n",
      "Epoch 43/200, Batch 400/1000, Time 6.386610s/(100 steps)\n",
      "Epoch 43/200, Batch 500/1000, Time 6.440467s/(100 steps)\n",
      "Epoch 43/200, Batch 600/1000, Time 6.472170s/(100 steps)\n",
      "Epoch 43/200, Batch 700/1000, Time 6.503107s/(100 steps)\n",
      "Epoch 43/200, Batch 800/1000, Time 6.352652s/(100 steps)\n",
      "Epoch 43/200, Batch 900/1000, Time 6.358625s/(100 steps)\n",
      "Epoch 43/200, Batch 1000/1000, Time 6.368358s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1572 - acc: 0.5938 - val_loss: 1.2251 - val_acc: 0.5985\n",
      "time 64.841008s\n",
      "Epoch 44/200, Batch 0/1000, Time 0.068934s/(100 steps)\n",
      "Epoch 44/200, Batch 100/1000, Time 6.310075s/(100 steps)\n",
      "Epoch 44/200, Batch 200/1000, Time 6.422211s/(100 steps)\n",
      "Epoch 44/200, Batch 300/1000, Time 6.409922s/(100 steps)\n",
      "Epoch 44/200, Batch 400/1000, Time 6.452162s/(100 steps)\n",
      "Epoch 44/200, Batch 500/1000, Time 6.368675s/(100 steps)\n",
      "Epoch 44/200, Batch 600/1000, Time 6.359568s/(100 steps)\n",
      "Epoch 44/200, Batch 700/1000, Time 7.373156s/(100 steps)\n",
      "Epoch 44/200, Batch 800/1000, Time 7.266319s/(100 steps)\n",
      "Epoch 44/200, Batch 900/1000, Time 7.132209s/(100 steps)\n",
      "Epoch 44/200, Batch 1000/1000, Time 7.480967s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 1.2610 - acc: 0.5234 - val_loss: 1.2269 - val_acc: 0.5946\n",
      "time 68.767852s\n",
      "Epoch 45/200, Batch 0/1000, Time 0.078335s/(100 steps)\n",
      "Epoch 45/200, Batch 100/1000, Time 7.262580s/(100 steps)\n",
      "Epoch 45/200, Batch 200/1000, Time 6.993508s/(100 steps)\n",
      "Epoch 45/200, Batch 300/1000, Time 7.334695s/(100 steps)\n",
      "Epoch 45/200, Batch 400/1000, Time 6.998095s/(100 steps)\n",
      "Epoch 45/200, Batch 500/1000, Time 7.122845s/(100 steps)\n",
      "Epoch 45/200, Batch 600/1000, Time 7.128849s/(100 steps)\n",
      "Epoch 45/200, Batch 700/1000, Time 7.046866s/(100 steps)\n",
      "Epoch 45/200, Batch 800/1000, Time 7.027880s/(100 steps)\n",
      "Epoch 45/200, Batch 900/1000, Time 7.182399s/(100 steps)\n",
      "Epoch 45/200, Batch 1000/1000, Time 7.235846s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.2884 - acc: 0.5938 - val_loss: 1.2232 - val_acc: 0.5948\n",
      "time 72.458023s\n",
      "Epoch 46/200, Batch 0/1000, Time 0.070429s/(100 steps)\n",
      "Epoch 46/200, Batch 100/1000, Time 6.384605s/(100 steps)\n",
      "Epoch 46/200, Batch 200/1000, Time 6.257068s/(100 steps)\n",
      "Epoch 46/200, Batch 300/1000, Time 6.353611s/(100 steps)\n",
      "Epoch 46/200, Batch 400/1000, Time 6.248568s/(100 steps)\n",
      "Epoch 46/200, Batch 500/1000, Time 6.258552s/(100 steps)\n",
      "Epoch 46/200, Batch 600/1000, Time 6.353634s/(100 steps)\n",
      "Epoch 46/200, Batch 700/1000, Time 6.284702s/(100 steps)\n",
      "Epoch 46/200, Batch 800/1000, Time 6.306283s/(100 steps)\n",
      "Epoch 46/200, Batch 900/1000, Time 6.245467s/(100 steps)\n",
      "Epoch 46/200, Batch 1000/1000, Time 6.255066s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2163 - acc: 0.5625 - val_loss: 1.2214 - val_acc: 0.5984\n",
      "time 63.536951s\n",
      "Epoch 47/200, Batch 0/1000, Time 0.061511s/(100 steps)\n",
      "Epoch 47/200, Batch 100/1000, Time 6.233011s/(100 steps)\n",
      "Epoch 47/200, Batch 200/1000, Time 6.230076s/(100 steps)\n",
      "Epoch 47/200, Batch 300/1000, Time 6.356751s/(100 steps)\n",
      "Epoch 47/200, Batch 400/1000, Time 6.185914s/(100 steps)\n",
      "Epoch 47/200, Batch 500/1000, Time 6.216540s/(100 steps)\n",
      "Epoch 47/200, Batch 600/1000, Time 6.224252s/(100 steps)\n",
      "Epoch 47/200, Batch 700/1000, Time 6.135473s/(100 steps)\n",
      "Epoch 47/200, Batch 800/1000, Time 6.134303s/(100 steps)\n",
      "Epoch 47/200, Batch 900/1000, Time 6.217267s/(100 steps)\n",
      "Epoch 47/200, Batch 1000/1000, Time 6.139528s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1395 - acc: 0.5938 - val_loss: 1.2328 - val_acc: 0.5969\n",
      "time 62.661706s\n",
      "Epoch 48/200, Batch 0/1000, Time 0.068562s/(100 steps)\n",
      "Epoch 48/200, Batch 100/1000, Time 6.318250s/(100 steps)\n",
      "Epoch 48/200, Batch 200/1000, Time 6.247885s/(100 steps)\n",
      "Epoch 48/200, Batch 300/1000, Time 6.244115s/(100 steps)\n",
      "Epoch 48/200, Batch 400/1000, Time 6.194632s/(100 steps)\n",
      "Epoch 48/200, Batch 500/1000, Time 6.271841s/(100 steps)\n",
      "Epoch 48/200, Batch 600/1000, Time 6.234876s/(100 steps)\n",
      "Epoch 48/200, Batch 700/1000, Time 6.180766s/(100 steps)\n",
      "Epoch 48/200, Batch 800/1000, Time 6.304101s/(100 steps)\n",
      "Epoch 48/200, Batch 900/1000, Time 6.305351s/(100 steps)\n",
      "Epoch 48/200, Batch 1000/1000, Time 6.258623s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2208 - acc: 0.5391 - val_loss: 1.2273 - val_acc: 0.5948\n",
      "time 63.148572s\n",
      "Epoch 49/200, Batch 0/1000, Time 0.062353s/(100 steps)\n",
      "Epoch 49/200, Batch 100/1000, Time 6.136188s/(100 steps)\n",
      "Epoch 49/200, Batch 200/1000, Time 6.172946s/(100 steps)\n",
      "Epoch 49/200, Batch 300/1000, Time 6.284438s/(100 steps)\n",
      "Epoch 49/200, Batch 400/1000, Time 6.196172s/(100 steps)\n",
      "Epoch 49/200, Batch 500/1000, Time 6.160664s/(100 steps)\n",
      "Epoch 49/200, Batch 600/1000, Time 6.227837s/(100 steps)\n",
      "Epoch 49/200, Batch 700/1000, Time 6.349454s/(100 steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200, Batch 800/1000, Time 6.257416s/(100 steps)\n",
      "Epoch 49/200, Batch 900/1000, Time 6.186263s/(100 steps)\n",
      "Epoch 49/200, Batch 1000/1000, Time 6.190573s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1829 - acc: 0.6250 - val_loss: 1.2140 - val_acc: 0.6026\n",
      "time 62.750333s\n",
      "Epoch 50/200, Batch 0/1000, Time 0.067233s/(100 steps)\n",
      "Epoch 50/200, Batch 100/1000, Time 6.210728s/(100 steps)\n",
      "Epoch 50/200, Batch 200/1000, Time 6.197123s/(100 steps)\n",
      "Epoch 50/200, Batch 300/1000, Time 6.280929s/(100 steps)\n",
      "Epoch 50/200, Batch 400/1000, Time 6.209601s/(100 steps)\n",
      "Epoch 50/200, Batch 500/1000, Time 6.182069s/(100 steps)\n",
      "Epoch 50/200, Batch 600/1000, Time 6.178025s/(100 steps)\n",
      "Epoch 50/200, Batch 700/1000, Time 6.172583s/(100 steps)\n",
      "Epoch 50/200, Batch 800/1000, Time 6.222229s/(100 steps)\n",
      "Epoch 50/200, Batch 900/1000, Time 6.190003s/(100 steps)\n",
      "Epoch 50/200, Batch 1000/1000, Time 6.202754s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3408 - acc: 0.5156 - val_loss: 1.2353 - val_acc: 0.5936\n",
      "time 62.631142s\n",
      "Epoch 51/200, Batch 0/1000, Time 0.061989s/(100 steps)\n",
      "Epoch 51/200, Batch 100/1000, Time 6.236308s/(100 steps)\n",
      "Epoch 51/200, Batch 200/1000, Time 6.213731s/(100 steps)\n",
      "Epoch 51/200, Batch 300/1000, Time 6.238611s/(100 steps)\n",
      "Epoch 51/200, Batch 400/1000, Time 6.160207s/(100 steps)\n",
      "Epoch 51/200, Batch 500/1000, Time 6.203996s/(100 steps)\n",
      "Epoch 51/200, Batch 600/1000, Time 6.286908s/(100 steps)\n",
      "Epoch 51/200, Batch 700/1000, Time 6.227974s/(100 steps)\n",
      "Epoch 51/200, Batch 800/1000, Time 6.250707s/(100 steps)\n",
      "Epoch 51/200, Batch 900/1000, Time 6.199901s/(100 steps)\n",
      "Epoch 51/200, Batch 1000/1000, Time 6.169891s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1167 - acc: 0.6250 - val_loss: 1.2194 - val_acc: 0.6000\n",
      "time 62.763185s\n",
      "Epoch 52/200, Batch 0/1000, Time 0.067700s/(100 steps)\n",
      "Epoch 52/200, Batch 100/1000, Time 6.157871s/(100 steps)\n",
      "Epoch 52/200, Batch 200/1000, Time 6.109157s/(100 steps)\n",
      "Epoch 52/200, Batch 300/1000, Time 6.188692s/(100 steps)\n",
      "Epoch 52/200, Batch 400/1000, Time 6.195453s/(100 steps)\n",
      "Epoch 52/200, Batch 500/1000, Time 6.166175s/(100 steps)\n",
      "Epoch 52/200, Batch 600/1000, Time 6.212692s/(100 steps)\n",
      "Epoch 52/200, Batch 700/1000, Time 6.192697s/(100 steps)\n",
      "Epoch 52/200, Batch 800/1000, Time 6.203282s/(100 steps)\n",
      "Epoch 52/200, Batch 900/1000, Time 6.186273s/(100 steps)\n",
      "Epoch 52/200, Batch 1000/1000, Time 6.255149s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1116 - acc: 0.6562 - val_loss: 1.2216 - val_acc: 0.5984\n",
      "time 62.465328s\n",
      "Epoch 53/200, Batch 0/1000, Time 0.067449s/(100 steps)\n",
      "Epoch 53/200, Batch 100/1000, Time 6.260017s/(100 steps)\n",
      "Epoch 53/200, Batch 200/1000, Time 6.194985s/(100 steps)\n",
      "Epoch 53/200, Batch 300/1000, Time 6.206187s/(100 steps)\n",
      "Epoch 53/200, Batch 400/1000, Time 6.229015s/(100 steps)\n",
      "Epoch 53/200, Batch 500/1000, Time 6.247448s/(100 steps)\n",
      "Epoch 53/200, Batch 600/1000, Time 6.243060s/(100 steps)\n",
      "Epoch 53/200, Batch 700/1000, Time 6.217205s/(100 steps)\n",
      "Epoch 53/200, Batch 800/1000, Time 6.289683s/(100 steps)\n",
      "Epoch 53/200, Batch 900/1000, Time 6.303605s/(100 steps)\n",
      "Epoch 53/200, Batch 1000/1000, Time 6.370862s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2592 - acc: 0.6250 - val_loss: 1.2013 - val_acc: 0.6103\n",
      "time 63.164587s\n",
      "Epoch 54/200, Batch 0/1000, Time 0.062935s/(100 steps)\n",
      "Epoch 54/200, Batch 100/1000, Time 6.484121s/(100 steps)\n",
      "Epoch 54/200, Batch 200/1000, Time 6.346419s/(100 steps)\n",
      "Epoch 54/200, Batch 300/1000, Time 6.592065s/(100 steps)\n",
      "Epoch 54/200, Batch 400/1000, Time 6.450794s/(100 steps)\n",
      "Epoch 54/200, Batch 500/1000, Time 6.644698s/(100 steps)\n",
      "Epoch 54/200, Batch 600/1000, Time 6.579697s/(100 steps)\n",
      "Epoch 54/200, Batch 700/1000, Time 6.491044s/(100 steps)\n",
      "Epoch 54/200, Batch 800/1000, Time 6.303826s/(100 steps)\n",
      "Epoch 54/200, Batch 900/1000, Time 6.309057s/(100 steps)\n",
      "Epoch 54/200, Batch 1000/1000, Time 6.401906s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2911 - acc: 0.5469 - val_loss: 1.2062 - val_acc: 0.6077\n",
      "time 65.208864s\n",
      "Epoch 55/200, Batch 0/1000, Time 0.064362s/(100 steps)\n",
      "Epoch 55/200, Batch 100/1000, Time 6.338740s/(100 steps)\n",
      "Epoch 55/200, Batch 200/1000, Time 6.402168s/(100 steps)\n",
      "Epoch 55/200, Batch 300/1000, Time 6.373581s/(100 steps)\n",
      "Epoch 55/200, Batch 400/1000, Time 6.290896s/(100 steps)\n",
      "Epoch 55/200, Batch 500/1000, Time 6.380640s/(100 steps)\n",
      "Epoch 55/200, Batch 600/1000, Time 6.383703s/(100 steps)\n",
      "Epoch 55/200, Batch 700/1000, Time 6.228764s/(100 steps)\n",
      "Epoch 55/200, Batch 800/1000, Time 6.250813s/(100 steps)\n",
      "Epoch 55/200, Batch 900/1000, Time 6.324713s/(100 steps)\n",
      "Epoch 55/200, Batch 1000/1000, Time 6.397104s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.4008 - acc: 0.5078 - val_loss: 1.2120 - val_acc: 0.6006\n",
      "time 63.960803s\n",
      "Epoch 56/200, Batch 0/1000, Time 0.061509s/(100 steps)\n",
      "Epoch 56/200, Batch 100/1000, Time 6.261074s/(100 steps)\n",
      "Epoch 56/200, Batch 200/1000, Time 6.318840s/(100 steps)\n",
      "Epoch 56/200, Batch 300/1000, Time 6.202485s/(100 steps)\n",
      "Epoch 56/200, Batch 400/1000, Time 6.148338s/(100 steps)\n",
      "Epoch 56/200, Batch 500/1000, Time 6.203123s/(100 steps)\n",
      "Epoch 56/200, Batch 600/1000, Time 6.187907s/(100 steps)\n",
      "Epoch 56/200, Batch 700/1000, Time 6.201432s/(100 steps)\n",
      "Epoch 56/200, Batch 800/1000, Time 6.198453s/(100 steps)\n",
      "Epoch 56/200, Batch 900/1000, Time 6.203234s/(100 steps)\n",
      "Epoch 56/200, Batch 1000/1000, Time 6.226914s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2081 - acc: 0.5859 - val_loss: 1.2014 - val_acc: 0.6119\n",
      "time 62.718488s\n",
      "Epoch 57/200, Batch 0/1000, Time 0.065634s/(100 steps)\n",
      "Epoch 57/200, Batch 100/1000, Time 6.221776s/(100 steps)\n",
      "Epoch 57/200, Batch 200/1000, Time 6.221872s/(100 steps)\n",
      "Epoch 57/200, Batch 300/1000, Time 6.235045s/(100 steps)\n",
      "Epoch 57/200, Batch 400/1000, Time 6.211982s/(100 steps)\n",
      "Epoch 57/200, Batch 500/1000, Time 6.207980s/(100 steps)\n",
      "Epoch 57/200, Batch 600/1000, Time 6.184556s/(100 steps)\n",
      "Epoch 57/200, Batch 700/1000, Time 6.174467s/(100 steps)\n",
      "Epoch 57/200, Batch 800/1000, Time 6.156987s/(100 steps)\n",
      "Epoch 57/200, Batch 900/1000, Time 6.220250s/(100 steps)\n",
      "Epoch 57/200, Batch 1000/1000, Time 6.173198s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2239 - acc: 0.6250 - val_loss: 1.2120 - val_acc: 0.6050\n",
      "time 62.591475s\n",
      "Epoch 58/200, Batch 0/1000, Time 0.067363s/(100 steps)\n",
      "Epoch 58/200, Batch 100/1000, Time 6.214073s/(100 steps)\n",
      "Epoch 58/200, Batch 200/1000, Time 6.271655s/(100 steps)\n",
      "Epoch 58/200, Batch 300/1000, Time 6.210541s/(100 steps)\n",
      "Epoch 58/200, Batch 400/1000, Time 6.167402s/(100 steps)\n",
      "Epoch 58/200, Batch 500/1000, Time 6.194828s/(100 steps)\n",
      "Epoch 58/200, Batch 600/1000, Time 6.181616s/(100 steps)\n",
      "Epoch 58/200, Batch 700/1000, Time 6.245981s/(100 steps)\n",
      "Epoch 58/200, Batch 800/1000, Time 6.393235s/(100 steps)\n",
      "Epoch 58/200, Batch 900/1000, Time 6.462170s/(100 steps)\n",
      "Epoch 58/200, Batch 1000/1000, Time 6.355655s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1648 - acc: 0.5938 - val_loss: 1.1938 - val_acc: 0.6141\n",
      "time 63.287045s\n",
      "Epoch 59/200, Batch 0/1000, Time 0.064808s/(100 steps)\n",
      "Epoch 59/200, Batch 100/1000, Time 6.259704s/(100 steps)\n",
      "Epoch 59/200, Batch 200/1000, Time 6.225852s/(100 steps)\n",
      "Epoch 59/200, Batch 300/1000, Time 6.377736s/(100 steps)\n",
      "Epoch 59/200, Batch 400/1000, Time 6.320818s/(100 steps)\n",
      "Epoch 59/200, Batch 500/1000, Time 6.160562s/(100 steps)\n",
      "Epoch 59/200, Batch 600/1000, Time 6.212275s/(100 steps)\n",
      "Epoch 59/200, Batch 700/1000, Time 6.199723s/(100 steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200, Batch 800/1000, Time 6.205597s/(100 steps)\n",
      "Epoch 59/200, Batch 900/1000, Time 6.224936s/(100 steps)\n",
      "Epoch 59/200, Batch 1000/1000, Time 6.244826s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1284 - acc: 0.6406 - val_loss: 1.2116 - val_acc: 0.6037\n",
      "time 63.001886s\n",
      "Epoch 60/200, Batch 0/1000, Time 0.067399s/(100 steps)\n",
      "Epoch 60/200, Batch 100/1000, Time 6.274858s/(100 steps)\n",
      "Epoch 60/200, Batch 200/1000, Time 6.193821s/(100 steps)\n",
      "Epoch 60/200, Batch 300/1000, Time 6.141530s/(100 steps)\n",
      "Epoch 60/200, Batch 400/1000, Time 6.162122s/(100 steps)\n",
      "Epoch 60/200, Batch 500/1000, Time 6.185116s/(100 steps)\n",
      "Epoch 60/200, Batch 600/1000, Time 6.195167s/(100 steps)\n",
      "Epoch 60/200, Batch 700/1000, Time 6.159047s/(100 steps)\n",
      "Epoch 60/200, Batch 800/1000, Time 6.169452s/(100 steps)\n",
      "Epoch 60/200, Batch 900/1000, Time 6.153997s/(100 steps)\n",
      "Epoch 60/200, Batch 1000/1000, Time 6.258403s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1798 - acc: 0.6406 - val_loss: 1.1966 - val_acc: 0.6125\n",
      "time 62.485483s\n",
      "Epoch 61/200, Batch 0/1000, Time 0.063366s/(100 steps)\n",
      "Epoch 61/200, Batch 100/1000, Time 6.274123s/(100 steps)\n",
      "Epoch 61/200, Batch 200/1000, Time 6.230942s/(100 steps)\n",
      "Epoch 61/200, Batch 300/1000, Time 6.203349s/(100 steps)\n",
      "Epoch 61/200, Batch 400/1000, Time 6.209456s/(100 steps)\n",
      "Epoch 61/200, Batch 500/1000, Time 6.457251s/(100 steps)\n",
      "Epoch 61/200, Batch 600/1000, Time 6.398869s/(100 steps)\n",
      "Epoch 61/200, Batch 700/1000, Time 6.426376s/(100 steps)\n",
      "Epoch 61/200, Batch 800/1000, Time 6.293051s/(100 steps)\n",
      "Epoch 61/200, Batch 900/1000, Time 6.206904s/(100 steps)\n",
      "Epoch 61/200, Batch 1000/1000, Time 6.411627s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.0659 - acc: 0.6875 - val_loss: 1.2195 - val_acc: 0.6010\n",
      "time 63.693374s\n",
      "Epoch 62/200, Batch 0/1000, Time 0.063391s/(100 steps)\n",
      "Epoch 62/200, Batch 100/1000, Time 6.432334s/(100 steps)\n",
      "Epoch 62/200, Batch 200/1000, Time 6.384235s/(100 steps)\n",
      "Epoch 62/200, Batch 300/1000, Time 6.302312s/(100 steps)\n",
      "Epoch 62/200, Batch 400/1000, Time 6.366276s/(100 steps)\n",
      "Epoch 62/200, Batch 500/1000, Time 6.314605s/(100 steps)\n",
      "Epoch 62/200, Batch 600/1000, Time 6.358497s/(100 steps)\n",
      "Epoch 62/200, Batch 700/1000, Time 6.346011s/(100 steps)\n",
      "Epoch 62/200, Batch 800/1000, Time 6.415967s/(100 steps)\n",
      "Epoch 62/200, Batch 900/1000, Time 6.375541s/(100 steps)\n",
      "Epoch 62/200, Batch 1000/1000, Time 6.338828s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2362 - acc: 0.6328 - val_loss: 1.2187 - val_acc: 0.6075\n",
      "time 64.218630s\n",
      "Epoch 63/200, Batch 0/1000, Time 0.067026s/(100 steps)\n",
      "Epoch 63/200, Batch 100/1000, Time 6.335402s/(100 steps)\n",
      "Epoch 63/200, Batch 200/1000, Time 6.326207s/(100 steps)\n",
      "Epoch 63/200, Batch 300/1000, Time 6.375622s/(100 steps)\n",
      "Epoch 63/200, Batch 400/1000, Time 6.366628s/(100 steps)\n",
      "Epoch 63/200, Batch 500/1000, Time 6.356343s/(100 steps)\n",
      "Epoch 63/200, Batch 600/1000, Time 6.365103s/(100 steps)\n",
      "Epoch 63/200, Batch 700/1000, Time 6.310539s/(100 steps)\n",
      "Epoch 63/200, Batch 800/1000, Time 6.301287s/(100 steps)\n",
      "Epoch 63/200, Batch 900/1000, Time 6.397393s/(100 steps)\n",
      "Epoch 63/200, Batch 1000/1000, Time 6.397565s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3392 - acc: 0.5547 - val_loss: 1.2202 - val_acc: 0.6006\n",
      "time 64.134171s\n",
      "Epoch 64/200, Batch 0/1000, Time 0.066249s/(100 steps)\n",
      "Epoch 64/200, Batch 100/1000, Time 6.407569s/(100 steps)\n",
      "Epoch 64/200, Batch 200/1000, Time 6.291974s/(100 steps)\n",
      "Epoch 64/200, Batch 300/1000, Time 6.320679s/(100 steps)\n",
      "Epoch 64/200, Batch 400/1000, Time 6.322202s/(100 steps)\n",
      "Epoch 64/200, Batch 500/1000, Time 6.302988s/(100 steps)\n",
      "Epoch 64/200, Batch 600/1000, Time 6.237247s/(100 steps)\n",
      "Epoch 64/200, Batch 700/1000, Time 6.268132s/(100 steps)\n",
      "Epoch 64/200, Batch 800/1000, Time 6.271614s/(100 steps)\n",
      "Epoch 64/200, Batch 900/1000, Time 6.213263s/(100 steps)\n",
      "Epoch 64/200, Batch 1000/1000, Time 6.336051s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.0288 - acc: 0.6797 - val_loss: 1.2189 - val_acc: 0.6077\n",
      "time 63.577875s\n",
      "Epoch 65/200, Batch 0/1000, Time 0.066891s/(100 steps)\n",
      "Epoch 65/200, Batch 100/1000, Time 6.430747s/(100 steps)\n",
      "Epoch 65/200, Batch 200/1000, Time 6.322231s/(100 steps)\n",
      "Epoch 65/200, Batch 300/1000, Time 6.332401s/(100 steps)\n",
      "Epoch 65/200, Batch 400/1000, Time 6.331520s/(100 steps)\n",
      "Epoch 65/200, Batch 500/1000, Time 6.372248s/(100 steps)\n",
      "Epoch 65/200, Batch 600/1000, Time 6.421265s/(100 steps)\n",
      "Epoch 65/200, Batch 700/1000, Time 6.401394s/(100 steps)\n",
      "Epoch 65/200, Batch 800/1000, Time 6.391789s/(100 steps)\n",
      "Epoch 65/200, Batch 900/1000, Time 6.444421s/(100 steps)\n",
      "Epoch 65/200, Batch 1000/1000, Time 6.394142s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2108 - acc: 0.6250 - val_loss: 1.2100 - val_acc: 0.6137\n",
      "time 64.425390s\n",
      "Epoch 66/200, Batch 0/1000, Time 0.061795s/(100 steps)\n",
      "Epoch 66/200, Batch 100/1000, Time 6.403473s/(100 steps)\n",
      "Epoch 66/200, Batch 200/1000, Time 6.400654s/(100 steps)\n",
      "Epoch 66/200, Batch 300/1000, Time 6.381724s/(100 steps)\n",
      "Epoch 66/200, Batch 400/1000, Time 6.355204s/(100 steps)\n",
      "Epoch 66/200, Batch 500/1000, Time 6.342497s/(100 steps)\n",
      "Epoch 66/200, Batch 600/1000, Time 6.350897s/(100 steps)\n",
      "Epoch 66/200, Batch 700/1000, Time 6.374662s/(100 steps)\n",
      "Epoch 66/200, Batch 800/1000, Time 6.335834s/(100 steps)\n",
      "Epoch 66/200, Batch 900/1000, Time 6.356114s/(100 steps)\n",
      "Epoch 66/200, Batch 1000/1000, Time 6.351308s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.0957 - acc: 0.6250 - val_loss: 1.2167 - val_acc: 0.6023\n",
      "time 64.233825s\n",
      "Epoch 67/200, Batch 0/1000, Time 0.062382s/(100 steps)\n",
      "Epoch 67/200, Batch 100/1000, Time 6.380327s/(100 steps)\n",
      "Epoch 67/200, Batch 200/1000, Time 6.342763s/(100 steps)\n",
      "Epoch 67/200, Batch 300/1000, Time 6.369735s/(100 steps)\n",
      "Epoch 67/200, Batch 400/1000, Time 6.362046s/(100 steps)\n",
      "Epoch 67/200, Batch 500/1000, Time 6.314011s/(100 steps)\n",
      "Epoch 67/200, Batch 600/1000, Time 6.329019s/(100 steps)\n",
      "Epoch 67/200, Batch 700/1000, Time 6.331843s/(100 steps)\n",
      "Epoch 67/200, Batch 800/1000, Time 6.297391s/(100 steps)\n",
      "Epoch 67/200, Batch 900/1000, Time 6.290156s/(100 steps)\n",
      "Epoch 67/200, Batch 1000/1000, Time 6.272909s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1395 - acc: 0.6719 - val_loss: 1.2180 - val_acc: 0.6062\n",
      "time 63.886442s\n",
      "Epoch 68/200, Batch 0/1000, Time 0.064340s/(100 steps)\n",
      "Epoch 68/200, Batch 100/1000, Time 6.345683s/(100 steps)\n",
      "Epoch 68/200, Batch 200/1000, Time 6.340641s/(100 steps)\n",
      "Epoch 68/200, Batch 300/1000, Time 6.442389s/(100 steps)\n",
      "Epoch 68/200, Batch 400/1000, Time 6.383225s/(100 steps)\n",
      "Epoch 68/200, Batch 500/1000, Time 6.360303s/(100 steps)\n",
      "Epoch 68/200, Batch 600/1000, Time 6.330199s/(100 steps)\n",
      "Epoch 68/200, Batch 700/1000, Time 6.338037s/(100 steps)\n",
      "Epoch 68/200, Batch 800/1000, Time 6.247461s/(100 steps)\n",
      "Epoch 68/200, Batch 900/1000, Time 6.236398s/(100 steps)\n",
      "Epoch 68/200, Batch 1000/1000, Time 6.256777s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1325 - acc: 0.6562 - val_loss: 1.2006 - val_acc: 0.6159\n",
      "time 63.882641s\n",
      "Epoch 69/200, Batch 0/1000, Time 0.065086s/(100 steps)\n",
      "Epoch 69/200, Batch 100/1000, Time 6.315943s/(100 steps)\n",
      "Epoch 69/200, Batch 200/1000, Time 6.310878s/(100 steps)\n",
      "Epoch 69/200, Batch 300/1000, Time 6.321533s/(100 steps)\n",
      "Epoch 69/200, Batch 400/1000, Time 6.359203s/(100 steps)\n",
      "Epoch 69/200, Batch 500/1000, Time 6.344941s/(100 steps)\n",
      "Epoch 69/200, Batch 600/1000, Time 6.295595s/(100 steps)\n",
      "Epoch 69/200, Batch 700/1000, Time 6.403034s/(100 steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200, Batch 800/1000, Time 6.351589s/(100 steps)\n",
      "Epoch 69/200, Batch 900/1000, Time 6.490607s/(100 steps)\n",
      "Epoch 69/200, Batch 1000/1000, Time 6.387399s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2270 - acc: 0.6016 - val_loss: 1.1945 - val_acc: 0.6191\n",
      "time 64.166771s\n",
      "Epoch 70/200, Batch 0/1000, Time 0.065667s/(100 steps)\n",
      "Epoch 70/200, Batch 100/1000, Time 6.418430s/(100 steps)\n",
      "Epoch 70/200, Batch 200/1000, Time 6.402650s/(100 steps)\n",
      "Epoch 70/200, Batch 300/1000, Time 6.380716s/(100 steps)\n",
      "Epoch 70/200, Batch 400/1000, Time 6.193431s/(100 steps)\n",
      "Epoch 70/200, Batch 500/1000, Time 6.283009s/(100 steps)\n",
      "Epoch 70/200, Batch 600/1000, Time 6.261611s/(100 steps)\n",
      "Epoch 70/200, Batch 700/1000, Time 6.268904s/(100 steps)\n",
      "Epoch 70/200, Batch 800/1000, Time 6.316630s/(100 steps)\n",
      "Epoch 70/200, Batch 900/1000, Time 6.339541s/(100 steps)\n",
      "Epoch 70/200, Batch 1000/1000, Time 6.270751s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3103 - acc: 0.5469 - val_loss: 1.1993 - val_acc: 0.6180\n",
      "time 63.710983s\n",
      "Epoch 71/200, Batch 0/1000, Time 0.063161s/(100 steps)\n",
      "Epoch 71/200, Batch 100/1000, Time 6.176950s/(100 steps)\n",
      "Epoch 71/200, Batch 200/1000, Time 6.280680s/(100 steps)\n",
      "Epoch 71/200, Batch 300/1000, Time 6.491107s/(100 steps)\n",
      "Epoch 71/200, Batch 400/1000, Time 6.335860s/(100 steps)\n",
      "Epoch 71/200, Batch 500/1000, Time 6.467354s/(100 steps)\n",
      "Epoch 71/200, Batch 600/1000, Time 6.421263s/(100 steps)\n",
      "Epoch 71/200, Batch 700/1000, Time 6.450442s/(100 steps)\n",
      "Epoch 71/200, Batch 800/1000, Time 6.342920s/(100 steps)\n",
      "Epoch 71/200, Batch 900/1000, Time 6.387437s/(100 steps)\n",
      "Epoch 71/200, Batch 1000/1000, Time 6.322526s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1263 - acc: 0.6250 - val_loss: 1.1929 - val_acc: 0.6162\n",
      "time 64.271417s\n",
      "Epoch 72/200, Batch 0/1000, Time 0.068476s/(100 steps)\n",
      "Epoch 72/200, Batch 100/1000, Time 6.431211s/(100 steps)\n",
      "Epoch 72/200, Batch 200/1000, Time 6.394094s/(100 steps)\n",
      "Epoch 72/200, Batch 300/1000, Time 6.259962s/(100 steps)\n",
      "Epoch 72/200, Batch 400/1000, Time 6.307205s/(100 steps)\n",
      "Epoch 72/200, Batch 500/1000, Time 6.364031s/(100 steps)\n",
      "Epoch 72/200, Batch 600/1000, Time 6.385463s/(100 steps)\n",
      "Epoch 72/200, Batch 700/1000, Time 6.403799s/(100 steps)\n",
      "Epoch 72/200, Batch 800/1000, Time 6.516363s/(100 steps)\n",
      "Epoch 72/200, Batch 900/1000, Time 6.579222s/(100 steps)\n",
      "Epoch 72/200, Batch 1000/1000, Time 6.371852s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.9989 - acc: 0.7109 - val_loss: 1.1960 - val_acc: 0.6184\n",
      "time 64.608793s\n",
      "Epoch 73/200, Batch 0/1000, Time 0.070882s/(100 steps)\n",
      "Epoch 73/200, Batch 100/1000, Time 6.348925s/(100 steps)\n",
      "Epoch 73/200, Batch 200/1000, Time 6.323680s/(100 steps)\n",
      "Epoch 73/200, Batch 300/1000, Time 6.211424s/(100 steps)\n",
      "Epoch 73/200, Batch 400/1000, Time 6.328302s/(100 steps)\n",
      "Epoch 73/200, Batch 500/1000, Time 6.302858s/(100 steps)\n",
      "Epoch 73/200, Batch 600/1000, Time 6.319664s/(100 steps)\n",
      "Epoch 73/200, Batch 700/1000, Time 6.259676s/(100 steps)\n",
      "Epoch 73/200, Batch 800/1000, Time 6.300973s/(100 steps)\n",
      "Epoch 73/200, Batch 900/1000, Time 6.345936s/(100 steps)\n",
      "Epoch 73/200, Batch 1000/1000, Time 6.344390s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2022 - acc: 0.6328 - val_loss: 1.1961 - val_acc: 0.6136\n",
      "time 63.691023s\n",
      "Epoch 74/200, Batch 0/1000, Time 0.065651s/(100 steps)\n",
      "Epoch 74/200, Batch 100/1000, Time 6.391167s/(100 steps)\n",
      "Epoch 74/200, Batch 200/1000, Time 6.302549s/(100 steps)\n",
      "Epoch 74/200, Batch 300/1000, Time 6.281081s/(100 steps)\n",
      "Epoch 74/200, Batch 400/1000, Time 6.181133s/(100 steps)\n",
      "Epoch 74/200, Batch 500/1000, Time 6.271693s/(100 steps)\n",
      "Epoch 74/200, Batch 600/1000, Time 6.214177s/(100 steps)\n",
      "Epoch 74/200, Batch 700/1000, Time 6.224911s/(100 steps)\n",
      "Epoch 74/200, Batch 800/1000, Time 6.229711s/(100 steps)\n",
      "Epoch 74/200, Batch 900/1000, Time 6.303356s/(100 steps)\n",
      "Epoch 74/200, Batch 1000/1000, Time 6.242439s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1765 - acc: 0.6406 - val_loss: 1.2109 - val_acc: 0.6105\n",
      "time 63.229392s\n",
      "Epoch 75/200, Batch 0/1000, Time 0.067166s/(100 steps)\n",
      "Epoch 75/200, Batch 100/1000, Time 6.251385s/(100 steps)\n",
      "Epoch 75/200, Batch 200/1000, Time 6.282155s/(100 steps)\n",
      "Epoch 75/200, Batch 300/1000, Time 6.286294s/(100 steps)\n",
      "Epoch 75/200, Batch 400/1000, Time 6.214021s/(100 steps)\n",
      "Epoch 75/200, Batch 500/1000, Time 6.285105s/(100 steps)\n",
      "Epoch 75/200, Batch 600/1000, Time 6.305167s/(100 steps)\n",
      "Epoch 75/200, Batch 700/1000, Time 6.370737s/(100 steps)\n",
      "Epoch 75/200, Batch 800/1000, Time 6.178264s/(100 steps)\n",
      "Epoch 75/200, Batch 900/1000, Time 6.369947s/(100 steps)\n",
      "Epoch 75/200, Batch 1000/1000, Time 6.483685s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1517 - acc: 0.6250 - val_loss: 1.1958 - val_acc: 0.6201\n",
      "time 63.627836s\n",
      "Epoch 76/200, Batch 0/1000, Time 0.070861s/(100 steps)\n",
      "Epoch 76/200, Batch 100/1000, Time 6.348917s/(100 steps)\n",
      "Epoch 76/200, Batch 200/1000, Time 6.388821s/(100 steps)\n",
      "Epoch 76/200, Batch 300/1000, Time 6.385415s/(100 steps)\n",
      "Epoch 76/200, Batch 400/1000, Time 6.304275s/(100 steps)\n",
      "Epoch 76/200, Batch 500/1000, Time 6.423422s/(100 steps)\n",
      "Epoch 76/200, Batch 600/1000, Time 6.298270s/(100 steps)\n",
      "Epoch 76/200, Batch 700/1000, Time 6.225820s/(100 steps)\n",
      "Epoch 76/200, Batch 800/1000, Time 6.264925s/(100 steps)\n",
      "Epoch 76/200, Batch 900/1000, Time 6.347620s/(100 steps)\n",
      "Epoch 76/200, Batch 1000/1000, Time 6.306535s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1900 - acc: 0.6094 - val_loss: 1.2020 - val_acc: 0.6224\n",
      "time 63.888964s\n",
      "Epoch 77/200, Batch 0/1000, Time 0.062332s/(100 steps)\n",
      "Epoch 77/200, Batch 100/1000, Time 6.294324s/(100 steps)\n",
      "Epoch 77/200, Batch 200/1000, Time 6.282214s/(100 steps)\n",
      "Epoch 77/200, Batch 300/1000, Time 6.253585s/(100 steps)\n",
      "Epoch 77/200, Batch 400/1000, Time 6.213780s/(100 steps)\n",
      "Epoch 77/200, Batch 500/1000, Time 6.265604s/(100 steps)\n",
      "Epoch 77/200, Batch 600/1000, Time 6.248001s/(100 steps)\n",
      "Epoch 77/200, Batch 700/1000, Time 6.259951s/(100 steps)\n",
      "Epoch 77/200, Batch 800/1000, Time 6.223779s/(100 steps)\n",
      "Epoch 77/200, Batch 900/1000, Time 6.248348s/(100 steps)\n",
      "Epoch 77/200, Batch 1000/1000, Time 6.311456s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.0562 - acc: 0.6875 - val_loss: 1.1981 - val_acc: 0.6086\n",
      "time 63.185463s\n",
      "Epoch 78/200, Batch 0/1000, Time 0.062310s/(100 steps)\n",
      "Epoch 78/200, Batch 100/1000, Time 6.410271s/(100 steps)\n",
      "Epoch 78/200, Batch 200/1000, Time 6.322671s/(100 steps)\n",
      "Epoch 78/200, Batch 300/1000, Time 6.336577s/(100 steps)\n",
      "Epoch 78/200, Batch 400/1000, Time 6.241969s/(100 steps)\n",
      "Epoch 78/200, Batch 500/1000, Time 6.268839s/(100 steps)\n",
      "Epoch 78/200, Batch 600/1000, Time 6.235821s/(100 steps)\n",
      "Epoch 78/200, Batch 700/1000, Time 6.239170s/(100 steps)\n",
      "Epoch 78/200, Batch 800/1000, Time 6.260977s/(100 steps)\n",
      "Epoch 78/200, Batch 900/1000, Time 6.327276s/(100 steps)\n",
      "Epoch 78/200, Batch 1000/1000, Time 6.345399s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2004 - acc: 0.5859 - val_loss: 1.1962 - val_acc: 0.6171\n",
      "time 63.589720s\n",
      "Epoch 79/200, Batch 0/1000, Time 0.067569s/(100 steps)\n",
      "Epoch 79/200, Batch 100/1000, Time 6.234210s/(100 steps)\n",
      "Epoch 79/200, Batch 200/1000, Time 6.304680s/(100 steps)\n",
      "Epoch 79/200, Batch 300/1000, Time 6.332795s/(100 steps)\n",
      "Epoch 79/200, Batch 400/1000, Time 6.394953s/(100 steps)\n",
      "Epoch 79/200, Batch 500/1000, Time 6.291974s/(100 steps)\n",
      "Epoch 79/200, Batch 600/1000, Time 6.310028s/(100 steps)\n",
      "Epoch 79/200, Batch 700/1000, Time 6.319689s/(100 steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200, Batch 800/1000, Time 6.224848s/(100 steps)\n",
      "Epoch 79/200, Batch 900/1000, Time 6.344258s/(100 steps)\n",
      "Epoch 79/200, Batch 1000/1000, Time 6.358792s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2971 - acc: 0.5391 - val_loss: 1.1898 - val_acc: 0.6207\n",
      "time 63.718594s\n",
      "Epoch 80/200, Batch 0/1000, Time 0.063675s/(100 steps)\n",
      "Epoch 80/200, Batch 100/1000, Time 6.323230s/(100 steps)\n",
      "Epoch 80/200, Batch 200/1000, Time 6.347629s/(100 steps)\n",
      "Epoch 80/200, Batch 300/1000, Time 6.372235s/(100 steps)\n",
      "Epoch 80/200, Batch 400/1000, Time 6.268157s/(100 steps)\n",
      "Epoch 80/200, Batch 500/1000, Time 6.419872s/(100 steps)\n",
      "Epoch 80/200, Batch 600/1000, Time 6.370048s/(100 steps)\n",
      "Epoch 80/200, Batch 700/1000, Time 6.404258s/(100 steps)\n",
      "Epoch 80/200, Batch 800/1000, Time 6.348323s/(100 steps)\n",
      "Epoch 80/200, Batch 900/1000, Time 6.400380s/(100 steps)\n",
      "Epoch 80/200, Batch 1000/1000, Time 6.483172s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1688 - acc: 0.6328 - val_loss: 1.1944 - val_acc: 0.6170\n",
      "time 64.339527s\n",
      "Epoch 81/200, Batch 0/1000, Time 0.066016s/(100 steps)\n",
      "Epoch 81/200, Batch 100/1000, Time 6.341465s/(100 steps)\n",
      "Epoch 81/200, Batch 200/1000, Time 6.376171s/(100 steps)\n",
      "Epoch 81/200, Batch 300/1000, Time 6.301022s/(100 steps)\n",
      "Epoch 81/200, Batch 400/1000, Time 6.268123s/(100 steps)\n",
      "Epoch 81/200, Batch 500/1000, Time 6.229492s/(100 steps)\n",
      "Epoch 81/200, Batch 600/1000, Time 6.236908s/(100 steps)\n",
      "Epoch 81/200, Batch 700/1000, Time 6.256715s/(100 steps)\n",
      "Epoch 81/200, Batch 800/1000, Time 6.271227s/(100 steps)\n",
      "Epoch 81/200, Batch 900/1000, Time 6.353576s/(100 steps)\n",
      "Epoch 81/200, Batch 1000/1000, Time 6.332072s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.0094 - acc: 0.6875 - val_loss: 1.1937 - val_acc: 0.6190\n",
      "time 63.549465s\n",
      "Epoch 82/200, Batch 0/1000, Time 0.063431s/(100 steps)\n",
      "Epoch 82/200, Batch 100/1000, Time 6.447095s/(100 steps)\n",
      "Epoch 82/200, Batch 200/1000, Time 6.495465s/(100 steps)\n",
      "Epoch 82/200, Batch 300/1000, Time 6.333024s/(100 steps)\n",
      "Epoch 82/200, Batch 400/1000, Time 6.425539s/(100 steps)\n",
      "Epoch 82/200, Batch 500/1000, Time 6.294231s/(100 steps)\n",
      "Epoch 82/200, Batch 600/1000, Time 6.410959s/(100 steps)\n",
      "Epoch 82/200, Batch 700/1000, Time 6.433023s/(100 steps)\n",
      "Epoch 82/200, Batch 800/1000, Time 6.252382s/(100 steps)\n",
      "Epoch 82/200, Batch 900/1000, Time 6.218363s/(100 steps)\n",
      "Epoch 82/200, Batch 1000/1000, Time 6.331387s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3480 - acc: 0.5781 - val_loss: 1.1931 - val_acc: 0.6203\n",
      "time 64.240187s\n",
      "Epoch 83/200, Batch 0/1000, Time 0.062074s/(100 steps)\n",
      "Epoch 83/200, Batch 100/1000, Time 6.255986s/(100 steps)\n",
      "Epoch 83/200, Batch 200/1000, Time 6.288802s/(100 steps)\n",
      "Epoch 83/200, Batch 300/1000, Time 6.275921s/(100 steps)\n",
      "Epoch 83/200, Batch 400/1000, Time 6.218470s/(100 steps)\n",
      "Epoch 83/200, Batch 500/1000, Time 6.396406s/(100 steps)\n",
      "Epoch 83/200, Batch 600/1000, Time 6.427783s/(100 steps)\n",
      "Epoch 83/200, Batch 700/1000, Time 6.394309s/(100 steps)\n",
      "Epoch 83/200, Batch 800/1000, Time 6.363982s/(100 steps)\n",
      "Epoch 83/200, Batch 900/1000, Time 6.346211s/(100 steps)\n",
      "Epoch 83/200, Batch 1000/1000, Time 6.340010s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2405 - acc: 0.5781 - val_loss: 1.1926 - val_acc: 0.6225\n",
      "time 63.899244s\n",
      "Epoch 84/200, Batch 0/1000, Time 0.065539s/(100 steps)\n",
      "Epoch 84/200, Batch 100/1000, Time 6.350220s/(100 steps)\n",
      "Epoch 84/200, Batch 200/1000, Time 6.294428s/(100 steps)\n",
      "Epoch 84/200, Batch 300/1000, Time 6.402231s/(100 steps)\n",
      "Epoch 84/200, Batch 400/1000, Time 6.261531s/(100 steps)\n",
      "Epoch 84/200, Batch 500/1000, Time 6.354760s/(100 steps)\n",
      "Epoch 84/200, Batch 600/1000, Time 6.325846s/(100 steps)\n",
      "Epoch 84/200, Batch 700/1000, Time 6.323055s/(100 steps)\n",
      "Epoch 84/200, Batch 800/1000, Time 6.365877s/(100 steps)\n",
      "Epoch 84/200, Batch 900/1000, Time 6.295608s/(100 steps)\n",
      "Epoch 84/200, Batch 1000/1000, Time 6.431765s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1750 - acc: 0.6172 - val_loss: 1.1956 - val_acc: 0.6201\n",
      "time 64.009239s\n",
      "Epoch 85/200, Batch 0/1000, Time 0.064992s/(100 steps)\n",
      "Epoch 85/200, Batch 100/1000, Time 6.267248s/(100 steps)\n",
      "Epoch 85/200, Batch 200/1000, Time 6.314788s/(100 steps)\n",
      "Epoch 85/200, Batch 300/1000, Time 6.332932s/(100 steps)\n",
      "Epoch 85/200, Batch 400/1000, Time 6.279739s/(100 steps)\n",
      "Epoch 85/200, Batch 500/1000, Time 6.297708s/(100 steps)\n",
      "Epoch 85/200, Batch 600/1000, Time 6.246555s/(100 steps)\n",
      "Epoch 85/200, Batch 700/1000, Time 6.266352s/(100 steps)\n",
      "Epoch 85/200, Batch 800/1000, Time 6.147073s/(100 steps)\n",
      "Epoch 85/200, Batch 900/1000, Time 6.246852s/(100 steps)\n",
      "Epoch 85/200, Batch 1000/1000, Time 6.243494s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1329 - acc: 0.6250 - val_loss: 1.1980 - val_acc: 0.6200\n",
      "time 63.245765s\n",
      "Epoch 86/200, Batch 0/1000, Time 0.066390s/(100 steps)\n",
      "Epoch 86/200, Batch 100/1000, Time 6.218849s/(100 steps)\n",
      "Epoch 86/200, Batch 200/1000, Time 6.215515s/(100 steps)\n",
      "Epoch 86/200, Batch 300/1000, Time 6.236638s/(100 steps)\n",
      "Epoch 86/200, Batch 400/1000, Time 6.316057s/(100 steps)\n",
      "Epoch 86/200, Batch 500/1000, Time 6.371979s/(100 steps)\n",
      "Epoch 86/200, Batch 600/1000, Time 6.309952s/(100 steps)\n",
      "Epoch 86/200, Batch 700/1000, Time 6.373885s/(100 steps)\n",
      "Epoch 86/200, Batch 800/1000, Time 6.314461s/(100 steps)\n",
      "Epoch 86/200, Batch 900/1000, Time 6.360468s/(100 steps)\n",
      "Epoch 86/200, Batch 1000/1000, Time 6.429706s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.0621 - acc: 0.6719 - val_loss: 1.2103 - val_acc: 0.6171\n",
      "time 63.745687s\n",
      "Epoch 87/200, Batch 0/1000, Time 0.066164s/(100 steps)\n",
      "Epoch 87/200, Batch 100/1000, Time 6.323128s/(100 steps)\n",
      "Epoch 87/200, Batch 200/1000, Time 6.418127s/(100 steps)\n",
      "Epoch 87/200, Batch 300/1000, Time 6.367356s/(100 steps)\n",
      "Epoch 87/200, Batch 400/1000, Time 6.283123s/(100 steps)\n",
      "Epoch 87/200, Batch 500/1000, Time 6.289661s/(100 steps)\n",
      "Epoch 87/200, Batch 600/1000, Time 6.349826s/(100 steps)\n",
      "Epoch 87/200, Batch 700/1000, Time 6.423970s/(100 steps)\n",
      "Epoch 87/200, Batch 800/1000, Time 6.307922s/(100 steps)\n",
      "Epoch 87/200, Batch 900/1000, Time 6.376932s/(100 steps)\n",
      "Epoch 87/200, Batch 1000/1000, Time 6.327827s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1338 - acc: 0.6016 - val_loss: 1.1873 - val_acc: 0.6242\n",
      "time 64.083593s\n",
      "Epoch 88/200, Batch 0/1000, Time 0.062788s/(100 steps)\n",
      "Epoch 88/200, Batch 100/1000, Time 6.416147s/(100 steps)\n",
      "Epoch 88/200, Batch 200/1000, Time 6.356745s/(100 steps)\n",
      "Epoch 88/200, Batch 300/1000, Time 6.339480s/(100 steps)\n",
      "Epoch 88/200, Batch 400/1000, Time 6.387416s/(100 steps)\n",
      "Epoch 88/200, Batch 500/1000, Time 6.432437s/(100 steps)\n",
      "Epoch 88/200, Batch 600/1000, Time 6.351032s/(100 steps)\n",
      "Epoch 88/200, Batch 700/1000, Time 6.335572s/(100 steps)\n",
      "Epoch 88/200, Batch 800/1000, Time 6.363917s/(100 steps)\n",
      "Epoch 88/200, Batch 900/1000, Time 6.381121s/(100 steps)\n",
      "Epoch 88/200, Batch 1000/1000, Time 6.355528s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1007 - acc: 0.7266 - val_loss: 1.2086 - val_acc: 0.6173\n",
      "time 64.293476s\n",
      "Epoch 89/200, Batch 0/1000, Time 0.066716s/(100 steps)\n",
      "Epoch 89/200, Batch 100/1000, Time 6.302488s/(100 steps)\n",
      "Epoch 89/200, Batch 200/1000, Time 6.309777s/(100 steps)\n",
      "Epoch 89/200, Batch 300/1000, Time 6.341148s/(100 steps)\n",
      "Epoch 89/200, Batch 400/1000, Time 6.347309s/(100 steps)\n",
      "Epoch 89/200, Batch 500/1000, Time 6.235405s/(100 steps)\n",
      "Epoch 89/200, Batch 600/1000, Time 6.330282s/(100 steps)\n",
      "Epoch 89/200, Batch 700/1000, Time 6.453825s/(100 steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200, Batch 800/1000, Time 6.445877s/(100 steps)\n",
      "Epoch 89/200, Batch 900/1000, Time 6.367348s/(100 steps)\n",
      "Epoch 89/200, Batch 1000/1000, Time 6.410792s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1675 - acc: 0.5938 - val_loss: 1.1965 - val_acc: 0.6197\n",
      "time 64.145523s\n",
      "Epoch 90/200, Batch 0/1000, Time 0.062192s/(100 steps)\n",
      "Epoch 90/200, Batch 100/1000, Time 6.372454s/(100 steps)\n",
      "Epoch 90/200, Batch 200/1000, Time 6.431317s/(100 steps)\n",
      "Epoch 90/200, Batch 300/1000, Time 6.345437s/(100 steps)\n",
      "Epoch 90/200, Batch 400/1000, Time 6.356574s/(100 steps)\n",
      "Epoch 90/200, Batch 500/1000, Time 6.244078s/(100 steps)\n",
      "Epoch 90/200, Batch 600/1000, Time 6.303826s/(100 steps)\n",
      "Epoch 90/200, Batch 700/1000, Time 6.264653s/(100 steps)\n",
      "Epoch 90/200, Batch 800/1000, Time 6.279315s/(100 steps)\n",
      "Epoch 90/200, Batch 900/1000, Time 6.329405s/(100 steps)\n",
      "Epoch 90/200, Batch 1000/1000, Time 6.343350s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1110 - acc: 0.6641 - val_loss: 1.2099 - val_acc: 0.6104\n",
      "time 63.858535s\n",
      "Epoch 91/200, Batch 0/1000, Time 0.060905s/(100 steps)\n",
      "Epoch 91/200, Batch 100/1000, Time 6.261559s/(100 steps)\n",
      "Epoch 91/200, Batch 200/1000, Time 6.406152s/(100 steps)\n",
      "Epoch 91/200, Batch 300/1000, Time 6.311153s/(100 steps)\n",
      "Epoch 91/200, Batch 400/1000, Time 6.296633s/(100 steps)\n",
      "Epoch 91/200, Batch 500/1000, Time 6.429460s/(100 steps)\n",
      "Epoch 91/200, Batch 600/1000, Time 6.302342s/(100 steps)\n",
      "Epoch 91/200, Batch 700/1000, Time 6.353951s/(100 steps)\n",
      "Epoch 91/200, Batch 800/1000, Time 6.328480s/(100 steps)\n",
      "Epoch 91/200, Batch 900/1000, Time 6.378270s/(100 steps)\n",
      "Epoch 91/200, Batch 1000/1000, Time 6.402793s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1037 - acc: 0.6719 - val_loss: 1.1925 - val_acc: 0.6187\n",
      "time 64.068854s\n",
      "Epoch 92/200, Batch 0/1000, Time 0.066576s/(100 steps)\n",
      "Epoch 92/200, Batch 100/1000, Time 6.285223s/(100 steps)\n",
      "Epoch 92/200, Batch 200/1000, Time 6.316308s/(100 steps)\n",
      "Epoch 92/200, Batch 300/1000, Time 6.292836s/(100 steps)\n",
      "Epoch 92/200, Batch 400/1000, Time 6.302082s/(100 steps)\n",
      "Epoch 92/200, Batch 500/1000, Time 6.293793s/(100 steps)\n",
      "Epoch 92/200, Batch 600/1000, Time 6.464140s/(100 steps)\n",
      "Epoch 92/200, Batch 700/1000, Time 6.222871s/(100 steps)\n",
      "Epoch 92/200, Batch 800/1000, Time 6.322909s/(100 steps)\n",
      "Epoch 92/200, Batch 900/1000, Time 6.261630s/(100 steps)\n",
      "Epoch 92/200, Batch 1000/1000, Time 6.225030s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2127 - acc: 0.5938 - val_loss: 1.1824 - val_acc: 0.6235\n",
      "time 63.585783s\n",
      "Epoch 93/200, Batch 0/1000, Time 0.065559s/(100 steps)\n",
      "Epoch 93/200, Batch 100/1000, Time 6.360542s/(100 steps)\n",
      "Epoch 93/200, Batch 200/1000, Time 6.450388s/(100 steps)\n",
      "Epoch 93/200, Batch 300/1000, Time 6.432809s/(100 steps)\n",
      "Epoch 93/200, Batch 400/1000, Time 6.433485s/(100 steps)\n",
      "Epoch 93/200, Batch 500/1000, Time 6.479311s/(100 steps)\n",
      "Epoch 93/200, Batch 600/1000, Time 6.346543s/(100 steps)\n",
      "Epoch 93/200, Batch 700/1000, Time 6.377130s/(100 steps)\n",
      "Epoch 93/200, Batch 800/1000, Time 6.353322s/(100 steps)\n",
      "Epoch 93/200, Batch 900/1000, Time 6.343108s/(100 steps)\n",
      "Epoch 93/200, Batch 1000/1000, Time 6.287893s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.0544 - acc: 0.6875 - val_loss: 1.2033 - val_acc: 0.6143\n",
      "time 64.450269s\n",
      "Epoch 94/200, Batch 0/1000, Time 0.060796s/(100 steps)\n",
      "Epoch 94/200, Batch 100/1000, Time 6.309079s/(100 steps)\n",
      "Epoch 94/200, Batch 200/1000, Time 6.308789s/(100 steps)\n",
      "Epoch 94/200, Batch 300/1000, Time 6.246559s/(100 steps)\n",
      "Epoch 94/200, Batch 400/1000, Time 6.218821s/(100 steps)\n",
      "Epoch 94/200, Batch 500/1000, Time 6.255007s/(100 steps)\n",
      "Epoch 94/200, Batch 600/1000, Time 6.422333s/(100 steps)\n",
      "Epoch 94/200, Batch 700/1000, Time 6.436073s/(100 steps)\n",
      "Epoch 94/200, Batch 800/1000, Time 6.317446s/(100 steps)\n",
      "Epoch 94/200, Batch 900/1000, Time 6.348021s/(100 steps)\n",
      "Epoch 94/200, Batch 1000/1000, Time 6.410736s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1295 - acc: 0.6406 - val_loss: 1.1884 - val_acc: 0.6220\n",
      "time 63.861338s\n",
      "Epoch 95/200, Batch 0/1000, Time 0.063465s/(100 steps)\n",
      "Epoch 95/200, Batch 100/1000, Time 6.374341s/(100 steps)\n",
      "Epoch 95/200, Batch 200/1000, Time 6.335078s/(100 steps)\n",
      "Epoch 95/200, Batch 300/1000, Time 6.526275s/(100 steps)\n",
      "Epoch 95/200, Batch 400/1000, Time 6.470396s/(100 steps)\n",
      "Epoch 95/200, Batch 500/1000, Time 6.306824s/(100 steps)\n",
      "Epoch 95/200, Batch 600/1000, Time 6.356707s/(100 steps)\n",
      "Epoch 95/200, Batch 700/1000, Time 6.374407s/(100 steps)\n",
      "Epoch 95/200, Batch 800/1000, Time 6.389457s/(100 steps)\n",
      "Epoch 95/200, Batch 900/1000, Time 6.286237s/(100 steps)\n",
      "Epoch 95/200, Batch 1000/1000, Time 6.272193s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.0347 - acc: 0.6406 - val_loss: 1.1894 - val_acc: 0.6185\n",
      "time 64.276942s\n",
      "Epoch 96/200, Batch 0/1000, Time 0.067066s/(100 steps)\n",
      "Epoch 96/200, Batch 100/1000, Time 6.367772s/(100 steps)\n",
      "Epoch 96/200, Batch 200/1000, Time 6.297939s/(100 steps)\n",
      "Epoch 96/200, Batch 300/1000, Time 6.248683s/(100 steps)\n",
      "Epoch 96/200, Batch 400/1000, Time 6.264429s/(100 steps)\n",
      "Epoch 96/200, Batch 500/1000, Time 6.269452s/(100 steps)\n",
      "Epoch 96/200, Batch 600/1000, Time 6.321979s/(100 steps)\n",
      "Epoch 96/200, Batch 700/1000, Time 6.410017s/(100 steps)\n",
      "Epoch 96/200, Batch 800/1000, Time 6.293980s/(100 steps)\n",
      "Epoch 96/200, Batch 900/1000, Time 6.237202s/(100 steps)\n",
      "Epoch 96/200, Batch 1000/1000, Time 6.289299s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1004 - acc: 0.6484 - val_loss: 1.1936 - val_acc: 0.6198\n",
      "time 63.601872s\n",
      "Epoch 97/200, Batch 0/1000, Time 0.069590s/(100 steps)\n",
      "Epoch 97/200, Batch 100/1000, Time 6.286220s/(100 steps)\n",
      "Epoch 97/200, Batch 200/1000, Time 6.239839s/(100 steps)\n",
      "Epoch 97/200, Batch 300/1000, Time 6.232404s/(100 steps)\n",
      "Epoch 97/200, Batch 400/1000, Time 6.215473s/(100 steps)\n",
      "Epoch 97/200, Batch 500/1000, Time 6.290500s/(100 steps)\n",
      "Epoch 97/200, Batch 600/1000, Time 6.305668s/(100 steps)\n",
      "Epoch 97/200, Batch 700/1000, Time 6.270892s/(100 steps)\n",
      "Epoch 97/200, Batch 800/1000, Time 6.236663s/(100 steps)\n",
      "Epoch 97/200, Batch 900/1000, Time 6.202024s/(100 steps)\n",
      "Epoch 97/200, Batch 1000/1000, Time 6.261028s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1821 - acc: 0.5859 - val_loss: 1.1890 - val_acc: 0.6232\n",
      "time 63.142570s\n",
      "Epoch 98/200, Batch 0/1000, Time 0.064363s/(100 steps)\n",
      "Epoch 98/200, Batch 100/1000, Time 6.332337s/(100 steps)\n",
      "Epoch 98/200, Batch 200/1000, Time 6.181781s/(100 steps)\n",
      "Epoch 98/200, Batch 300/1000, Time 6.193315s/(100 steps)\n",
      "Epoch 98/200, Batch 400/1000, Time 6.189079s/(100 steps)\n",
      "Epoch 98/200, Batch 500/1000, Time 6.221840s/(100 steps)\n",
      "Epoch 98/200, Batch 600/1000, Time 6.296971s/(100 steps)\n",
      "Epoch 98/200, Batch 700/1000, Time 6.190180s/(100 steps)\n",
      "Epoch 98/200, Batch 800/1000, Time 6.241177s/(100 steps)\n",
      "Epoch 98/200, Batch 900/1000, Time 6.350613s/(100 steps)\n",
      "Epoch 98/200, Batch 1000/1000, Time 6.341949s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.3059 - acc: 0.5625 - val_loss: 1.1922 - val_acc: 0.6222\n",
      "time 63.126006s\n",
      "Epoch 99/200, Batch 0/1000, Time 0.066819s/(100 steps)\n",
      "Epoch 99/200, Batch 100/1000, Time 6.231329s/(100 steps)\n",
      "Epoch 99/200, Batch 200/1000, Time 6.280980s/(100 steps)\n",
      "Epoch 99/200, Batch 300/1000, Time 6.220447s/(100 steps)\n",
      "Epoch 99/200, Batch 400/1000, Time 6.275998s/(100 steps)\n",
      "Epoch 99/200, Batch 500/1000, Time 6.258418s/(100 steps)\n",
      "Epoch 99/200, Batch 600/1000, Time 6.354828s/(100 steps)\n",
      "Epoch 99/200, Batch 700/1000, Time 6.314598s/(100 steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200, Batch 800/1000, Time 6.261708s/(100 steps)\n",
      "Epoch 99/200, Batch 900/1000, Time 6.263270s/(100 steps)\n",
      "Epoch 99/200, Batch 1000/1000, Time 6.311180s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.0558 - acc: 0.6562 - val_loss: 1.1844 - val_acc: 0.6274\n",
      "time 63.353742s\n",
      "Epoch 100/200, Batch 0/1000, Time 0.067579s/(100 steps)\n",
      "Epoch 100/200, Batch 100/1000, Time 6.222256s/(100 steps)\n",
      "Epoch 100/200, Batch 200/1000, Time 6.202484s/(100 steps)\n",
      "Epoch 100/200, Batch 300/1000, Time 6.229452s/(100 steps)\n",
      "Epoch 100/200, Batch 400/1000, Time 6.271571s/(100 steps)\n",
      "Epoch 100/200, Batch 500/1000, Time 6.330204s/(100 steps)\n",
      "Epoch 100/200, Batch 600/1000, Time 6.352223s/(100 steps)\n",
      "Epoch 100/200, Batch 700/1000, Time 6.309391s/(100 steps)\n",
      "Epoch 100/200, Batch 800/1000, Time 6.244361s/(100 steps)\n",
      "Epoch 100/200, Batch 900/1000, Time 6.307629s/(100 steps)\n",
      "Epoch 100/200, Batch 1000/1000, Time 6.348714s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.0017 - acc: 0.6641 - val_loss: 1.1803 - val_acc: 0.6304\n",
      "time 63.415015s\n",
      "Epoch 101/200, Batch 0/1000, Time 0.065313s/(100 steps)\n",
      "Epoch 101/200, Batch 100/1000, Time 6.351175s/(100 steps)\n",
      "Epoch 101/200, Batch 200/1000, Time 6.384099s/(100 steps)\n",
      "Epoch 101/200, Batch 300/1000, Time 6.355669s/(100 steps)\n",
      "Epoch 101/200, Batch 400/1000, Time 6.329983s/(100 steps)\n",
      "Epoch 101/200, Batch 500/1000, Time 6.293037s/(100 steps)\n",
      "Epoch 101/200, Batch 600/1000, Time 6.362040s/(100 steps)\n",
      "Epoch 101/200, Batch 700/1000, Time 6.297046s/(100 steps)\n",
      "Epoch 101/200, Batch 800/1000, Time 6.293803s/(100 steps)\n",
      "Epoch 101/200, Batch 900/1000, Time 6.324664s/(100 steps)\n",
      "Epoch 101/200, Batch 1000/1000, Time 6.202656s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.1383 - acc: 0.6562 - val_loss: 1.1884 - val_acc: 0.6267\n",
      "time 63.798154s\n",
      "Epoch 102/200, Batch 0/1000, Time 0.059736s/(100 steps)\n",
      "Epoch 102/200, Batch 100/1000, Time 6.198985s/(100 steps)\n",
      "Epoch 102/200, Batch 200/1000, Time 6.325231s/(100 steps)\n",
      "Epoch 102/200, Batch 300/1000, Time 6.418549s/(100 steps)\n",
      "Epoch 102/200, Batch 400/1000, Time 6.289545s/(100 steps)\n",
      "Epoch 102/200, Batch 500/1000, Time 6.284628s/(100 steps)\n",
      "Epoch 102/200, Batch 600/1000, Time 6.233101s/(100 steps)\n",
      "Epoch 102/200, Batch 700/1000, Time 6.230241s/(100 steps)\n",
      "Epoch 102/200, Batch 800/1000, Time 6.287668s/(100 steps)\n",
      "Epoch 102/200, Batch 900/1000, Time 6.281383s/(100 steps)\n",
      "Epoch 102/200, Batch 1000/1000, Time 6.308899s/(100 steps)\n",
      "Train on 128 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 1.2411 - acc: 0.5703 - val_loss: 1.1857 - val_acc: 0.6245\n",
      "time 63.449163s\n",
      "Epoch 103/200, Batch 0/1000, Time 0.060949s/(100 steps)\n",
      "Epoch 103/200, Batch 100/1000, Time 6.268114s/(100 steps)\n",
      "Epoch 103/200, Batch 200/1000, Time 6.298436s/(100 steps)\n",
      "Epoch 103/200, Batch 300/1000, Time 6.305657s/(100 steps)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b212fdfb4272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0meptime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mbtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3072\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    148\u001b[0m                            dtype=self.dtype)\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             x = self.image_data_generator.apply_transform(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "MLP on CIFAR10 dataset\n",
    "    63% Validation Accuracy @Epoch 100\n",
    "    NOTE: Code was halted due not setting the max epoch to 100\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from keras import backend as K\n",
    "if K.backend() == 'tensorflow': #prevents out CUDA out of memory\n",
    "    import tensorflow as tf\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "stime = time.time()\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "x_train_legacy = x_train\n",
    "y_train_legacy = y_train\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.reshape(50000, 3072)\n",
    "x_test = x_test.reshape(10000, 3072)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "\n",
    "kernel_regularizer = l2(0.0001)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu',kernel_regularizer=kernel_regularizer, input_shape=(3072,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=kernel_regularizer))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu', kernel_regularizer=kernel_regularizer))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "opt = keras.optimizers.adam(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "data_augmentation = True\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    x_train = np.reshape(x_train, [-1, 32, 32, 3])\n",
    "    datagen = ImageDataGenerator(\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n",
    "        fill_mode='nearest',\n",
    "        horizontal_flip=True  # randomly flip images\n",
    "        )\n",
    "\n",
    "\n",
    "    datagen.fit(x_train)\n",
    "    \n",
    "    max_batches = 1000\n",
    "    for e in range(epochs):\n",
    "        batches = 0\n",
    "        eptime = time.time()\n",
    "        btime = time.time()\n",
    "        for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=batch_size):\n",
    "            \n",
    "            x_batch = np.reshape(x_batch, [-1, 3072])\n",
    "            model.fit(x_batch, y_batch, verbose=0)\n",
    "            \n",
    "            if batches%(max_batches//10) == 0 :\n",
    "                print(\"Epoch %d/%d, Batch %d/%d, Time %fs/(100 steps)\" % (e+1, epochs, batches, max_batches, time.time()-btime))\n",
    "                btime = time.time()\n",
    "            batches += 1\n",
    "            if batches-1 >= max_batches:\n",
    "                model.fit(x_batch, y_batch,validation_data=(x_test, y_test), verbose=1)\n",
    "                break\n",
    "        print(\"time %fs\" % (time.time()-eptime))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "etime = time.time()\n",
    "print('Time taken in min: ', (etime-stime)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
